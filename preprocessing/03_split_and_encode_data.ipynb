{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11531217,"sourceType":"datasetVersion","datasetId":7232568}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\ndf = pd.read_csv(\"/kaggle/input/noaa-powout-prism-0-1-is-storm-lag/noaapowoutprism_01_Is_Storm_Lag (1).csv\")\n\n# Split into 80% (train+test) and 20% (holdout)\ntrain_test, holdout_data = train_test_split(df, test_size=0.2, random_state=42)\n\n# Split train_test into 70% train and 10% test (out of total)\n# Since train_test is 80%, we calculate relative proportions\nrelative_test_size = 0.1 / 0.8  # = 0.125 of train_test\ntrain_data, test_data = train_test_split(train_test, test_size=relative_test_size, random_state=42)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-14T22:21:46.843505Z","iopub.execute_input":"2025-05-14T22:21:46.843765Z","iopub.status.idle":"2025-05-14T22:21:59.378572Z","shell.execute_reply.started":"2025-05-14T22:21:46.843737Z","shell.execute_reply":"2025-05-14T22:21:59.377547Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Combine datasets for consistent encoding\ndata = pd.concat([train_data, test_data, holdout_data], ignore_index=True)\n\n# Encoding using DAMAGE_PROPERTY (numerical, non-target variable)\ncategorical_cols = ['EVENT_TYPE', 'stability', 'WFO']\nencoding_maps = {}\n\n# Compute encoding mappings from training data using DAMAGE_PROPERTY\nfor col in categorical_cols:\n    if col in train_data.columns:\n        encoding_maps[col] = train_data.groupby(col)['ppt'].mean() \n\n# Apply encoding to combined data\nfor col in categorical_cols:\n    if col in data.columns:\n        data[col + '_encoded'] = data[col].map(encoding_maps[col]).fillna(train_data['ppt'].mean())\n\n# Split back into train, test, holdout\ntrain_data = data.iloc[:len(train_data)]\ntest_data = data.iloc[len(train_data):len(train_data) + len(test_data)]\nholdout_data = data.iloc[len(train_data) + len(test_data):]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T22:22:05.554263Z","iopub.execute_input":"2025-05-14T22:22:05.554631Z","iopub.status.idle":"2025-05-14T22:22:05.776289Z","shell.execute_reply.started":"2025-05-14T22:22:05.554605Z","shell.execute_reply":"2025-05-14T22:22:05.775100Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Export\ntrain_data.to_csv(\"/kaggle/working/train.csv\", index=False)\ntest_data.to_csv(\"/kaggle/working/test.csv\", index=False)\nholdout_data.to_csv(\"/kaggle/working/holdout.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T22:22:34.323793Z","iopub.execute_input":"2025-05-14T22:22:34.324157Z","iopub.status.idle":"2025-05-14T22:22:50.707296Z","shell.execute_reply.started":"2025-05-14T22:22:34.324129Z","shell.execute_reply":"2025-05-14T22:22:50.706610Z"}},"outputs":[],"execution_count":3}]}