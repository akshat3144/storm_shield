{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11641464,"sourceType":"datasetVersion","datasetId":7304854},{"sourceId":368636,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":305346,"modelId":325799},{"sourceId":368659,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":305362,"modelId":325815},{"sourceId":369364,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":305881,"modelId":326328},{"sourceId":369393,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":305909,"modelId":326355},{"sourceId":369449,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":305954,"modelId":326398}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1) Storm Prediction","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport joblib\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n\n# Load data\ndata = pd.read_csv('/kaggle/input/mlpr-data-split/holdout.csv')\n\n# Define features\nstorm_features = [\n    'DEATHS_INDIRECT', 'INJURIES_DIRECT', 'INJURIES_INDIRECT', 'DEATHS_DIRECT',\n    'DAMAGE_PROPERTY', 'DAMAGE_CROPS', 'customers_out', 'duration_hours',\n    'desc_word_count', 'desc_char_count',\n    'has_tornado', 'has_hail', 'has_flood', 'has_wind', 'has_tree',\n    'has_power', 'has_damage', 'has_outage', 'has_broken', 'has_blown',\n    'tmin', 'tmax', 'tavg', 'ppt'\n]\ntarget_col = 'is_storm_lagged'\n\n# Load storm model and scaler\nstorm_model = joblib.load('/kaggle/input/storm_rf_model-1/scikitlearn/default/1/storm_rf_model (1).pkl')\nscaler = joblib.load('/kaggle/input/storm_rf_model-1/scikitlearn/default/1/storm_scaler.pkl')\n\n# Prepare features and scale\nX = data[storm_features].values  # Convert to NumPy array to avoid feature name warning\nX_scaled = scaler.transform(X)    # Apply scaling\n\n# Storm prediction\nstorm_preds = storm_model.predict(X_scaled)\n\n# Add predictions to DataFrame\ndata['predicted_storm'] = storm_preds\n\n# Evaluate model\ny_true = data[target_col]\ny_pred = data['predicted_storm']\naccuracy = accuracy_score(y_true, y_pred)\nprecision = precision_score(y_true, y_pred, zero_division=0)\nrecall = recall_score(y_true, y_pred, zero_division=0)\nf1 = f1_score(y_true, y_pred, zero_division=0)\nconf_matrix = confusion_matrix(y_true, y_pred)\n\nprint(\"Storm Prediction Metrics:\")\nprint(f\"Accuracy : {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall   : {recall:.4f}\")\nprint(f\"F1 Score : {f1:.4f}\")\nprint(\"\\nConfusion Matrix:\")\nprint(conf_matrix)\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_true, y_pred, zero_division=0))\n\n# Filter storm cases\nstorm_data = data[data['predicted_storm'] == 1].copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T10:58:23.602978Z","iopub.execute_input":"2025-05-02T10:58:23.603308Z","iopub.status.idle":"2025-05-02T10:58:31.832068Z","shell.execute_reply.started":"2025-05-02T10:58:23.603282Z","shell.execute_reply":"2025-05-02T10:58:31.831007Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Storm Prediction Metrics:\nAccuracy : 0.9066\nPrecision: 0.9103\nRecall   : 0.9073\nF1 Score : 0.9088\n\nConfusion Matrix:\n[[18566  1927]\n [ 1999 19563]]\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.90      0.91      0.90     20493\n           1       0.91      0.91      0.91     21562\n\n    accuracy                           0.91     42055\n   macro avg       0.91      0.91      0.91     42055\nweighted avg       0.91      0.91      0.91     42055\n\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# 2) Severity Prediction","metadata":{}},{"cell_type":"code","source":"# Filter out unexpected class labels\nvalid_classes = [0, 1, 2]\nstorm_data = storm_data[storm_data['severity_class'].isin(valid_classes)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T10:58:31.833443Z","iopub.execute_input":"2025-05-02T10:58:31.833773Z","iopub.status.idle":"2025-05-02T10:58:31.850040Z","shell.execute_reply.started":"2025-05-02T10:58:31.833750Z","shell.execute_reply":"2025-05-02T10:58:31.849374Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# ----------------- SEVERITY PREDICTION -----------------\n\n# Define severity features\nseverity_features = [\n    'DEATHS_INDIRECT', 'INJURIES_DIRECT', 'INJURIES_INDIRECT', 'DEATHS_DIRECT',\n    'DAMAGE_PROPERTY', 'DAMAGE_CROPS', 'customers_out', 'duration_hours',\n    'desc_word_count', 'desc_char_count',\n    'has_tornado', 'has_hail', 'has_flood', 'has_wind', 'has_tree',\n    'has_power', 'has_damage', 'has_outage', 'has_broken', 'has_blown',\n    'tmin', 'tmax', 'tavg', 'ppt'\n]\ntarget_col = 'severity_class'\n\n# Load severity model and scaler\nseverity_model = joblib.load('/kaggle/input/severity_xg_model/scikitlearn/default/1/severity_xg_model.pkl')\nseverity_scaler = joblib.load('/kaggle/input/severity_xg_model/scikitlearn/default/1/severity_scaler (1).pkl')\n\n# Prepare features and scale\nX = storm_data[severity_features].values\nX_scaled = severity_scaler.transform(X)\n\n# Severity prediction\nseverity_preds = severity_model.predict(X_scaled)\nstorm_data['predicted_severity'] = severity_preds\n\n# Evaluate severity model\ny_true = storm_data[target_col]\ny_pred = storm_data['predicted_severity']\naccuracy = accuracy_score(y_true, y_pred)\nprecision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\nrecall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\nf1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\nconf_matrix = confusion_matrix(y_true, y_pred)\n\nprint(\"Severity Prediction Metrics:\")\nprint(f\"Accuracy : {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall   : {recall:.4f}\")\nprint(f\"F1 Score : {f1:.4f}\")\nprint(\"\\nConfusion Matrix:\")\nprint(conf_matrix)\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_true, y_pred, zero_division=0))\n\n# Filter severity cases\nlow_severity_data = storm_data[storm_data['predicted_severity'] == 0].copy()\nmed_severity_data = storm_data[storm_data['predicted_severity'] == 1].copy()\nhigh_severity_data = storm_data[storm_data['predicted_severity'] == 2].copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T10:58:31.850915Z","iopub.execute_input":"2025-05-02T10:58:31.851241Z","iopub.status.idle":"2025-05-02T10:58:33.072966Z","shell.execute_reply.started":"2025-05-02T10:58:31.851211Z","shell.execute_reply":"2025-05-02T10:58:33.071988Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Severity Prediction Metrics:\nAccuracy : 0.8592\nPrecision: 0.8591\nRecall   : 0.8592\nF1 Score : 0.8591\n\nConfusion Matrix:\n[[5961  304  323]\n [ 346 5208  762]\n [ 314  704 5628]]\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.90      0.90      0.90      6588\n           1       0.84      0.82      0.83      6316\n           2       0.84      0.85      0.84      6646\n\n    accuracy                           0.86     19550\n   macro avg       0.86      0.86      0.86     19550\nweighted avg       0.86      0.86      0.86     19550\n\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# 3) Outage Prediction","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\n# Derive is_outage target (assuming customers_out > 0 indicates an outage)\nfor df in [low_severity_data, med_severity_data, high_severity_data]:\n    df['is_outage'] = (df['customers_out'] > 0).astype(int)\n\n# Extract non-storm rows from storm_df_with_predictions\nnon_storm_data = data[data['is_storm_lagged'] == 0].copy()\nnon_storm_data['is_outage'] = 0  # No outage for non-storm events\nnon_storm_data['predicted_severity'] = 10  # Placeholder for non-storm rows\n\n# Randomly split non-storm rows across the three DataFrames\nnon_storm_split = np.array_split(non_storm_data.sample(frac=1, random_state=42), 3)\nnon_storm_low, non_storm_medium, non_storm_high = non_storm_split\n\n# Augment DataFrames with non-storm rows\nlow_severity_data = pd.concat([low_severity_data, non_storm_low], ignore_index=True)\nmed_severity_data = pd.concat([med_severity_data, non_storm_medium], ignore_index=True)\nhigh_severity_data = pd.concat([high_severity_data, non_storm_high], ignore_index=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T10:58:33.075083Z","iopub.execute_input":"2025-05-02T10:58:33.075397Z","iopub.status.idle":"2025-05-02T10:58:33.156729Z","shell.execute_reply.started":"2025-05-02T10:58:33.075373Z","shell.execute_reply":"2025-05-02T10:58:33.155904Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n  return bound(*args, **kwds)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"outage_features = [\n    'tmin', 'tmax', 'tavg', 'ppt',\n    'has_tornado', 'has_hail', 'has_flood', 'has_wind', 'has_tree',\n    'DAMAGE_PROPERTY', 'DAMAGE_CROPS', 'duration_hours',\n    'desc_word_count', 'desc_char_count'\n]\n\ntarget_col = 'is_outage'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T10:58:33.157603Z","iopub.execute_input":"2025-05-02T10:58:33.157901Z","iopub.status.idle":"2025-05-02T10:58:33.162339Z","shell.execute_reply.started":"2025-05-02T10:58:33.157879Z","shell.execute_reply":"2025-05-02T10:58:33.161343Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"### a. Low","metadata":{}},{"cell_type":"code","source":"import joblib\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n\n# ----------------- LOAD MODEL AND SCALER -----------------\noutage_model = joblib.load('/kaggle/input/low_severity_lgm_model/scikitlearn/default/1/low_severity_lgm_model.pkl')\nscaler = joblib.load('/kaggle/input/low_severity_lgm_model/scikitlearn/default/1/low_severity_scaler (1).pkl')\n\n# ----------------- PREPARE FEATURES -----------------\noutage_features = [\n    'tmin', 'tmax', 'tavg', 'ppt',\n    'has_tornado', 'has_hail', 'has_flood', 'has_wind', 'has_tree',\n    'DAMAGE_PROPERTY', 'DAMAGE_CROPS', 'duration_hours',\n    'desc_word_count', 'desc_char_count'\n]\nX = low_severity_data[outage_features]\n\n# ----------------- SCALE FEATURES -----------------\nX_scaled = scaler.transform(X)\n\n# ----------------- SEVERITY PREDICTION -----------------\noutage_pred = outage_model.predict(X_scaled)\n\n# ----------------- TRUE AND PREDICTED LABELS -----------------\ntarget_col = 'is_outage'  # Assuming this is the target column based on prior context\ny_true_outage = low_severity_data[target_col]\ny_pred_outage = outage_pred\n\n# ----------------- METRIC CALCULATIONS -----------------\naccuracy = accuracy_score(y_true_outage, y_pred_outage)\nprecision = precision_score(y_true_outage, y_pred_outage, average='binary', zero_division=0)\nrecall = recall_score(y_true_outage, y_pred_outage, average='binary', zero_division=0)\nf1 = f1_score(y_true_outage, y_pred_outage, average='binary', zero_division=0)\nconf_matrix = confusion_matrix(y_true_outage, y_pred_outage)\n\n# ----------------- OUTPUT -----------------\nprint(\"Outage Prediction Metrics:\")\nprint(f\"Accuracy : {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall   : {recall:.4f}\")\nprint(f\"F1 Score : {f1:.4f}\")\nprint(\"\\nConfusion Matrix:\")\nprint(conf_matrix)\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_true_outage, y_pred_outage, zero_division=0))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T10:58:33.163261Z","iopub.execute_input":"2025-05-02T10:58:33.163577Z","iopub.status.idle":"2025-05-02T10:58:42.078140Z","shell.execute_reply.started":"2025-05-02T10:58:33.163550Z","shell.execute_reply":"2025-05-02T10:58:42.077123Z"}},"outputs":[{"name":"stdout","text":"Outage Prediction Metrics:\nAccuracy : 0.9645\nPrecision: 0.9433\nRecall   : 0.9870\nF1 Score : 0.9646\n\nConfusion Matrix:\n[[6470  391]\n [  86 6505]]\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.99      0.94      0.96      6861\n           1       0.94      0.99      0.96      6591\n\n    accuracy                           0.96     13452\n   macro avg       0.97      0.96      0.96     13452\nweighted avg       0.97      0.96      0.96     13452\n\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"### b. Medium","metadata":{}},{"cell_type":"code","source":"import joblib\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n\n# ----------------- LOAD MODEL AND SCALER -----------------\noutage_model = joblib.load('/kaggle/input/medium_severity_rf_model-1/scikitlearn/default/1/medium_severity_rf_model (1).pkl')\nscaler = joblib.load('/kaggle/input/medium_severity_rf_model-1/scikitlearn/default/1/medium_severity_scaler.pkl')\n\n# ----------------- PREPARE FEATURES -----------------\noutage_features = [\n    'tmin', 'tmax', 'tavg', 'ppt',\n    'has_tornado', 'has_hail', 'has_flood', 'has_wind', 'has_tree',\n    'DAMAGE_PROPERTY', 'DAMAGE_CROPS', 'duration_hours',\n    'desc_word_count', 'desc_char_count'\n]\nX = med_severity_data[outage_features]\n\n# ----------------- SCALE FEATURES -----------------\nX_scaled = scaler.transform(X)\n\n# ----------------- SEVERITY PREDICTION -----------------\noutage_pred = outage_model.predict(X_scaled)\n\n# ----------------- TRUE AND PREDICTED LABELS -----------------\ntarget_col = 'is_outage'  # Assuming this is the target column based on prior context\ny_true_outage = med_severity_data[target_col]\ny_pred_outage = outage_pred\n\n# ----------------- METRIC CALCULATIONS -----------------\naccuracy = accuracy_score(y_true_outage, y_pred_outage)\nprecision = precision_score(y_true_outage, y_pred_outage, average='binary', zero_division=0)\nrecall = recall_score(y_true_outage, y_pred_outage, average='binary', zero_division=0)\nf1 = f1_score(y_true_outage, y_pred_outage, average='binary', zero_division=0)\nconf_matrix = confusion_matrix(y_true_outage, y_pred_outage)\n\n# ----------------- OUTPUT -----------------\nprint(\"Outage Prediction Metrics:\")\nprint(f\"Accuracy : {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall   : {recall:.4f}\")\nprint(f\"F1 Score : {f1:.4f}\")\nprint(\"\\nConfusion Matrix:\")\nprint(conf_matrix)\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_true_outage, y_pred_outage, zero_division=0))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T10:58:42.079230Z","iopub.execute_input":"2025-05-02T10:58:42.080747Z","iopub.status.idle":"2025-05-02T10:58:43.408561Z","shell.execute_reply.started":"2025-05-02T10:58:42.080705Z","shell.execute_reply":"2025-05-02T10:58:43.407583Z"}},"outputs":[{"name":"stdout","text":"Outage Prediction Metrics:\nAccuracy : 0.9471\nPrecision: 0.9225\nRecall   : 0.9704\nF1 Score : 0.9458\n\nConfusion Matrix:\n[[6334  506]\n [ 184 6023]]\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.97      0.93      0.95      6840\n           1       0.92      0.97      0.95      6207\n\n    accuracy                           0.95     13047\n   macro avg       0.95      0.95      0.95     13047\nweighted avg       0.95      0.95      0.95     13047\n\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"### c. High","metadata":{}},{"cell_type":"code","source":"import joblib\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\nimport numpy as np  # Add numpy for thresholding\n\n# ----------------- LOAD MODEL AND SCALER -----------------\noutage_model = joblib.load('/kaggle/input/high_severity_fnn_model/tensorflow2/default/1/high_severity_fnn_model.pkl')\nscaler = joblib.load('/kaggle/input/high_severity_fnn_model/tensorflow2/default/1/high_severity_scaler (1).pkl')\n\n# ----------------- PREPARE FEATURES -----------------\noutage_features = [\n    'tmin', 'tmax', 'tavg', 'ppt',\n    'has_tornado', 'has_hail', 'has_flood', 'has_wind', 'has_tree',\n    'DAMAGE_PROPERTY', 'DAMAGE_CROPS', 'duration_hours',\n    'desc_word_count', 'desc_char_count'\n]\nX = high_severity_data[outage_features]\n\n# ----------------- SCALE FEATURES -----------------\nX_scaled = scaler.transform(X)\n\n# ----------------- SEVERITY PREDICTION -----------------\noutage_pred = outage_model.predict(X_scaled)\n\n# ----------------- THRESHOLD PREDICTIONS -----------------\n# Convert continuous predictions to binary (0 or 1) using 0.5 threshold\ny_pred_outage = (outage_pred >= 0.5).astype(int)\n\n# ----------------- TRUE AND PREDICTED LABELS -----------------\ntarget_col = 'is_outage'\ny_true_outage = high_severity_data[target_col]\n\n# ----------------- METRIC CALCULATIONS -----------------\naccuracy = accuracy_score(y_true_outage, y_pred_outage)\nprecision = precision_score(y_true_outage, y_pred_outage, average='binary', zero_division=0)\nrecall = recall_score(y_true_outage, y_pred_outage, average='binary', zero_division=0)\nf1 = f1_score(y_true_outage, y_pred_outage, average='binary', zero_division=0)\nconf_matrix = confusion_matrix(y_true_outage, y_pred_outage)\n\n# ----------------- OUTPUT -----------------\nprint(\"Outage Prediction Metrics:\")\nprint(f\"Accuracy : {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall   : {recall:.4f}\")\nprint(f\"F1 Score : {f1:.4f}\")\nprint(\"\\nConfusion Matrix:\")\nprint(conf_matrix)\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_true_outage, y_pred_outage, zero_division=0))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T10:58:43.409471Z","iopub.execute_input":"2025-05-02T10:58:43.409794Z","iopub.status.idle":"2025-05-02T10:58:59.946754Z","shell.execute_reply.started":"2025-05-02T10:58:43.409770Z","shell.execute_reply":"2025-05-02T10:58:59.945770Z"}},"outputs":[{"name":"stderr","text":"2025-05-02 10:58:45.241795: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746183525.478206      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746183525.543069      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-05-02 10:58:58.754476: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\nOutage Prediction Metrics:\nAccuracy : 0.8754\nPrecision: 0.8248\nRecall   : 0.9492\nF1 Score : 0.8826\n\nConfusion Matrix:\n[[5508 1348]\n [ 340 6348]]\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.94      0.80      0.87      6856\n           1       0.82      0.95      0.88      6688\n\n    accuracy                           0.88     13544\n   macro avg       0.88      0.88      0.87     13544\nweighted avg       0.88      0.88      0.87     13544\n\n","output_type":"stream"}],"execution_count":8}]}