{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11531217,"sourceType":"datasetVersion","datasetId":7232568}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n\nstorm_df = pd.read_csv(\"/kaggle/input/noaa-powout-prism-0-1-is-storm-lag/noaapowoutprism_01_Is_Storm_Lag (1).csv\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-02T13:08:43.935916Z","iopub.execute_input":"2025-05-02T13:08:43.936197Z","iopub.status.idle":"2025-05-02T13:08:55.009978Z","shell.execute_reply.started":"2025-05-02T13:08:43.936168Z","shell.execute_reply":"2025-05-02T13:08:55.008956Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# Storm Prediction","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\n\n# Define features\nstorm_features = [\n    'DEATHS_INDIRECT', 'INJURIES_DIRECT', 'INJURIES_INDIRECT', 'DEATHS_DIRECT',\n    'DAMAGE_PROPERTY', 'DAMAGE_CROPS', 'customers_out', 'duration_hours',\n    'desc_word_count', 'desc_char_count',\n    'has_tornado', 'has_hail', 'has_flood', 'has_wind', 'has_tree',\n    'has_power', 'has_damage', 'has_outage', 'has_broken', 'has_blown',\n    'tmin', 'tmax', 'tavg', 'ppt'\n]\n\n# Prepare X and y\nX = storm_df[storm_features]\ny = storm_df['is_storm_lagged'].astype(int)\n\n# Scale features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T13:09:20.221610Z","iopub.execute_input":"2025-05-02T13:09:20.222329Z","iopub.status.idle":"2025-05-02T13:09:20.830981Z","shell.execute_reply.started":"2025-05-02T13:09:20.222295Z","shell.execute_reply":"2025-05-02T13:09:20.830233Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Train Random Forest model on all data with best hyperparameters obtained using optuna\nrf_model = RandomForestClassifier(\n    n_estimators=188,\n    max_depth=50,\n    min_samples_split=2,\n    min_samples_leaf=1,\n    max_features='log2',\n    bootstrap=False,\n    random_state=42,\n    n_jobs=-1\n)\nrf_model.fit(X_scaled, y)\n\n# Predict on all data\npredictions = rf_model.predict(X_scaled)\n\n# Create new DataFrame with predictions\nstorm_df_with_predictions = storm_df.copy()\nstorm_df_with_predictions['predicted_storm'] = predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T13:09:28.071083Z","iopub.execute_input":"2025-05-02T13:09:28.071715Z","iopub.status.idle":"2025-05-02T13:10:22.429051Z","shell.execute_reply.started":"2025-05-02T13:09:28.071688Z","shell.execute_reply":"2025-05-02T13:10:22.428351Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"storm_df_with_1_predictions = storm_df_with_predictions[storm_df_with_predictions['predicted_storm'] == 1].copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T13:10:22.430254Z","iopub.execute_input":"2025-05-02T13:10:22.430506Z","iopub.status.idle":"2025-05-02T13:10:22.529705Z","shell.execute_reply.started":"2025-05-02T13:10:22.430484Z","shell.execute_reply":"2025-05-02T13:10:22.528798Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Severity Prediction","metadata":{}},{"cell_type":"code","source":"# Filter out unexpected class labels\nvalid_classes = [0, 1, 2]\nstorm_df_with_1_predictions = storm_df_with_1_predictions[storm_df_with_1_predictions['severity_class'].isin(valid_classes)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T13:12:43.834315Z","iopub.execute_input":"2025-05-02T13:12:43.834651Z","iopub.status.idle":"2025-05-02T13:12:43.872306Z","shell.execute_reply.started":"2025-05-02T13:12:43.834628Z","shell.execute_reply":"2025-05-02T13:12:43.871404Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\nseverity_features = [\n    # Original impact features\n    'DEATHS_INDIRECT', 'INJURIES_DIRECT', 'INJURIES_INDIRECT', 'DEATHS_DIRECT',\n    'DAMAGE_PROPERTY', 'DAMAGE_CROPS', 'customers_out', 'duration_hours',\n\n    # NLP-derived features\n    'desc_word_count', 'desc_char_count',\n    'has_tornado', 'has_hail', 'has_flood', 'has_wind', 'has_tree',\n    'has_power', 'has_damage', 'has_outage', 'has_broken', 'has_blown',\n\n    #prism features\n    'tmin', 'tmax', 'tavg', 'ppt'\n]\n\n# Features and target\nX = storm_df_with_1_predictions[severity_features]\ny = storm_df_with_1_predictions['severity_class']\n\n# Scale features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\nX_scaled = scaler.transform(X)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T13:12:46.511125Z","iopub.execute_input":"2025-05-02T13:12:46.511932Z","iopub.status.idle":"2025-05-02T13:12:46.583469Z","shell.execute_reply.started":"2025-05-02T13:12:46.511905Z","shell.execute_reply":"2025-05-02T13:12:46.582594Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom xgboost import XGBClassifier\n\n# Train XGBoost classifier on all data\nxgb_model = XGBClassifier(\n    n_estimators=403,\n    max_depth=10,\n    learning_rate=0.09065400280278058,\n    subsample=0.933968095670629,\n    colsample_bytree=0.5647574078202744,\n    gamma=0.00017586655077512627,\n    min_child_weight=2,\n    use_label_encoder=False,\n    eval_metric='logloss',\n    random_state=42\n)\nxgb_model.fit(X_scaled, y)\n\n# Predict on the full dataset\npredictions = xgb_model.predict(X_scaled)\n\nstorm_data_with_severity = storm_df_with_1_predictions.copy()\nstorm_data_with_severity['severity_predicted'] = predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T13:13:54.251033Z","iopub.execute_input":"2025-05-02T13:13:54.251352Z","iopub.status.idle":"2025-05-02T13:14:14.013230Z","shell.execute_reply.started":"2025-05-02T13:13:54.251331Z","shell.execute_reply":"2025-05-02T13:14:14.012591Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Create three DataFrames based on predicted severity\ndf_low = storm_data_with_severity[storm_data_with_severity['severity_predicted'] == 0]\ndf_medium = storm_data_with_severity[storm_data_with_severity['severity_predicted'] == 1]\ndf_high = storm_data_with_severity[storm_data_with_severity['severity_predicted'] == 2]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T13:14:22.421048Z","iopub.execute_input":"2025-05-02T13:14:22.421352Z","iopub.status.idle":"2025-05-02T13:14:22.465782Z","shell.execute_reply.started":"2025-05-02T13:14:22.421332Z","shell.execute_reply":"2025-05-02T13:14:22.464969Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"# Outage Prediction","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nimport lightgbm as lgb\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense\n\n# Define outage features (common for all models)\noutage_features = [\n    'tmin', 'tmax', 'tavg', 'ppt',\n    'has_tornado', 'has_hail', 'has_flood', 'has_wind', 'has_tree',\n    'DAMAGE_PROPERTY', 'DAMAGE_CROPS', 'duration_hours',\n    'desc_word_count', 'desc_char_count'\n]\n\n# Derive is_outage target (assuming customers_out > 0 indicates an outage)\nfor df in [df_low, df_medium, df_high]:\n    df['is_outage'] = (df['customers_out'] > 0).astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T13:14:26.121103Z","iopub.execute_input":"2025-05-02T13:14:26.121392Z","iopub.status.idle":"2025-05-02T13:14:47.416990Z","shell.execute_reply.started":"2025-05-02T13:14:26.121373Z","shell.execute_reply":"2025-05-02T13:14:47.416058Z"}},"outputs":[{"name":"stderr","text":"2025-05-02 13:14:33.495024: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746191673.717526      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746191673.786328      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/tmp/ipykernel_31/1656639219.py:21: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df['is_outage'] = (df['customers_out'] > 0).astype(int)\n/tmp/ipykernel_31/1656639219.py:21: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df['is_outage'] = (df['customers_out'] > 0).astype(int)\n/tmp/ipykernel_31/1656639219.py:21: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df['is_outage'] = (df['customers_out'] > 0).astype(int)\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Extract non-storm rows from storm_df_with_predictions\nnon_storm_data = storm_df_with_predictions[storm_df_with_predictions['predicted_storm'] == 0].copy()\nnon_storm_data['is_outage'] = 0  # No outage for non-storm events\nnon_storm_data['severity_predicted'] = 10  # Placeholder for non-storm rows","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T13:14:47.418569Z","iopub.execute_input":"2025-05-02T13:14:47.419591Z","iopub.status.idle":"2025-05-02T13:14:47.524147Z","shell.execute_reply.started":"2025-05-02T13:14:47.419556Z","shell.execute_reply":"2025-05-02T13:14:47.523408Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Randomly split non-storm rows across the three DataFrames\nnon_storm_split = np.array_split(non_storm_data.sample(frac=1, random_state=42), 3)\nnon_storm_low, non_storm_medium, non_storm_high = non_storm_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T13:14:47.524924Z","iopub.execute_input":"2025-05-02T13:14:47.525238Z","iopub.status.idle":"2025-05-02T13:14:47.659953Z","shell.execute_reply.started":"2025-05-02T13:14:47.525213Z","shell.execute_reply":"2025-05-02T13:14:47.659259Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n  return bound(*args, **kwds)\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Augment DataFrames with non-storm rows\ndf_low = pd.concat([df_low, non_storm_low], ignore_index=True)\ndf_medium = pd.concat([df_medium, non_storm_medium], ignore_index=True)\ndf_high = pd.concat([df_high, non_storm_high], ignore_index=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T13:14:47.661381Z","iopub.execute_input":"2025-05-02T13:14:47.661681Z","iopub.status.idle":"2025-05-02T13:14:47.708930Z","shell.execute_reply.started":"2025-05-02T13:14:47.661662Z","shell.execute_reply":"2025-05-02T13:14:47.707887Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"### Low Severity","metadata":{}},{"cell_type":"code","source":"if not df_low.empty:\n    X_low = df_low[outage_features]\n    y_low = df_low['is_outage']\n    \n    # Train-test split\n    X_train_low, X_test_low, y_train_low, y_test_low = train_test_split(\n        X_low, y_low, test_size=0.2, stratify=y_low, random_state=42\n    )\n    \n    # Feature scaling\n    scaler_low = StandardScaler()\n    X_train_low_scaled = scaler_low.fit_transform(X_train_low)\n    X_test_low_scaled = scaler_low.transform(X_test_low)\n\n    # Best parameters from Optuna Trial 32\n    best_params = {\n        'n_estimators': 319,\n        'learning_rate': 0.047847333909262976,\n        'num_leaves': 281,\n        'max_depth': 20,\n        'min_child_samples': 22,\n        'subsample': 0.527136639688917,\n        'colsample_bytree': 0.8326768083509417,\n        'random_state': 42\n    }\n\n    # Train final LightGBM model\n    final_lgb_model = lgb.LGBMClassifier(**best_params)\n    final_lgb_model.fit(X_train_low_scaled, y_train_low)\n    \n    # Predictions\n    low_predictions = final_lgb_model.predict(X_test_low_scaled)\n    \n    # Evaluation\n    print(\"Final Tuned LightGBM (Low Severity) Metrics:\")\n    print(\"Accuracy:\", accuracy_score(y_test_low, low_predictions))\n    print(\"Classification Report:\\n\", classification_report(y_test_low, low_predictions))\n    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_low, low_predictions))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T13:15:02.561321Z","iopub.execute_input":"2025-05-02T13:15:02.561662Z","iopub.status.idle":"2025-05-02T13:15:08.914872Z","shell.execute_reply.started":"2025-05-02T13:15:02.561640Z","shell.execute_reply":"2025-05-02T13:15:08.914042Z"}},"outputs":[{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 25874, number of negative: 27885\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007830 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2097\n[LightGBM] [Info] Number of data points in the train set: 53759, number of used features: 14\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.481296 -> initscore=-0.074850\n[LightGBM] [Info] Start training from score -0.074850\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nFinal Tuned LightGBM (Low Severity) Metrics:\nAccuracy: 0.9529761904761904\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.96      0.95      0.95      6971\n           1       0.95      0.96      0.95      6469\n\n    accuracy                           0.95     13440\n   macro avg       0.95      0.95      0.95     13440\nweighted avg       0.95      0.95      0.95     13440\n\nConfusion Matrix:\n [[6618  353]\n [ 279 6190]]\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"### Medium Severity","metadata":{}},{"cell_type":"code","source":"if not df_medium.empty:\n    X_medium = df_medium[outage_features]\n    y_medium = df_medium['is_outage']\n    \n    # Train-test split\n    X_train_medium, X_test_medium, y_train_medium, y_test_medium = train_test_split(\n        X_medium, y_medium, test_size=0.2, stratify=y_medium, random_state=42\n    )\n    \n    # Scale features\n    scaler_medium = StandardScaler()\n    X_train_medium_scaled = scaler_medium.fit_transform(X_train_medium)\n    X_test_medium_scaled = scaler_medium.transform(X_test_medium)\n    \n    # Train Random Forest\n    rf_model = RandomForestClassifier(\n        n_estimators=191,\n        max_depth=28,\n        min_samples_split=6,\n        min_samples_leaf=2,\n        max_features='log2',\n        bootstrap=False,\n        random_state=42,\n        n_jobs=-1\n    )\n    rf_model.fit(X_train_medium_scaled, y_train_medium)\n    \n    # Predict on test set\n    medium_predictions = rf_model.predict(X_test_medium_scaled)\n    \n    # Evaluate\n    print(\"\\nRandom Forest (Medium Severity) Metrics:\")\n    print(\"Accuracy:\", accuracy_score(y_test_medium, medium_predictions))\n    print(\"Classification Report:\\n\", classification_report(y_test_medium, medium_predictions))\n    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_medium, medium_predictions))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T13:15:28.161214Z","iopub.execute_input":"2025-05-02T13:15:28.162001Z","iopub.status.idle":"2025-05-02T13:15:38.357701Z","shell.execute_reply.started":"2025-05-02T13:15:28.161976Z","shell.execute_reply":"2025-05-02T13:15:38.356802Z"}},"outputs":[{"name":"stdout","text":"\nRandom Forest (Medium Severity) Metrics:\nAccuracy: 0.9362767760826013\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.95      0.93      0.94      6958\n           1       0.92      0.95      0.93      6020\n\n    accuracy                           0.94     12978\n   macro avg       0.94      0.94      0.94     12978\nweighted avg       0.94      0.94      0.94     12978\n\nConfusion Matrix:\n [[6459  499]\n [ 328 5692]]\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"### High Severity","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\nif not df_high.empty:\n    X_high = df_high[outage_features]\n    y_high = df_high['is_outage']\n\n    # Train-test split\n    X_train_high, X_test_high, y_train_high, y_test_high = train_test_split(\n        X_high, y_high, test_size=0.2, stratify=y_high, random_state=42\n    )\n\n    # Scale features\n    scaler_high = StandardScaler()\n    X_train_high_scaled = scaler_high.fit_transform(X_train_high)\n    X_test_high_scaled = scaler_high.transform(X_test_high)\n\n    # Optimized hyperparameters from Optuna\n    n_units = [80, 112, 96]\n    dropout_rate = 0.1677425146431672\n    learning_rate = 0.001715383587455835\n    batch_size = 64\n\n    # Build optimized model\n    model = Sequential()\n    model.add(Dense(n_units[0], activation='relu', input_shape=(len(outage_features),)))\n    model.add(Dropout(dropout_rate))\n    model.add(Dense(n_units[1], activation='relu'))\n    model.add(Dropout(dropout_rate))\n    model.add(Dense(n_units[2], activation='relu'))\n    model.add(Dense(1, activation='sigmoid'))\n\n    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n\n    model.fit(\n        X_train_high_scaled, y_train_high,\n        epochs=20,\n        batch_size=batch_size,\n        validation_split=0.2,\n        verbose=0\n    )\n\n    # Predict on test set\n    high_predictions = (model.predict(X_test_high_scaled) > 0.5).astype(int).flatten()\n\n    # Evaluation\n    print(\"\\nOptimized FNN (High Severity) Metrics:\")\n    print(\"Accuracy:\", accuracy_score(y_test_high, high_predictions))\n    print(\"Classification Report:\\n\", classification_report(y_test_high, high_predictions))\n    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_high, high_predictions))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T13:16:02.406127Z","iopub.execute_input":"2025-05-02T13:16:02.406795Z","iopub.status.idle":"2025-05-02T13:16:35.377278Z","shell.execute_reply.started":"2025-05-02T13:16:02.406770Z","shell.execute_reply":"2025-05-02T13:16:35.376378Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n2025-05-02 13:16:02.482375: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m419/419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n\nOptimized FNN (High Severity) Metrics:\nAccuracy: 0.8671245147805315\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.90      0.84      0.87      6958\n           1       0.84      0.90      0.87      6438\n\n    accuracy                           0.87     13396\n   macro avg       0.87      0.87      0.87     13396\nweighted avg       0.87      0.87      0.87     13396\n\nConfusion Matrix:\n [[5829 1129]\n [ 651 5787]]\n","output_type":"stream"}],"execution_count":19}]}