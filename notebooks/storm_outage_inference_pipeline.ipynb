{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11641464,"sourceType":"datasetVersion","datasetId":7304854},{"sourceId":391083,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":322046,"modelId":342690},{"sourceId":391688,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":322511,"modelId":343201},{"sourceId":392113,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":322858,"modelId":343546},{"sourceId":392130,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":322873,"modelId":343559},{"sourceId":392135,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":322877,"modelId":343563}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport joblib\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n\n# Load data\ntrain_data = pd.read_csv('/kaggle/input/mlpr-data-split/train.csv')\ntest_data = pd.read_csv('/kaggle/input/mlpr-data-split/test.csv')\nholdout_data = pd.read_csv('/kaggle/input/mlpr-data-split/holdout.csv')\n\n# Combine datasets for consistent encoding\ndata = pd.concat([train_data, test_data, holdout_data], ignore_index=True)\n\n# Encoding using DAMAGE_PROPERTY (numerical, non-target variable)\ncategorical_cols = ['EVENT_TYPE', 'stability', 'WFO']\nencoding_maps = {}\n\n# Compute encoding mappings from training data using DAMAGE_PROPERTY\nfor col in categorical_cols:\n    if col in train_data.columns:\n        encoding_maps[col] = train_data.groupby(col)['ppt'].mean() \n\n# Apply encoding to combined data\nfor col in categorical_cols:\n    if col in data.columns:\n        data[col + '_encoded'] = data[col].map(encoding_maps[col]).fillna(train_data['ppt'].mean())\n\n# Split back into train, test, holdout\ntrain_data = data.iloc[:len(train_data)]\ntest_data = data.iloc[len(train_data):len(train_data) + len(test_data)]\nholdout_data = data.iloc[len(train_data) + len(test_data):]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T14:04:16.535595Z","iopub.execute_input":"2025-05-14T14:04:16.536177Z","iopub.status.idle":"2025-05-14T14:04:27.012111Z","shell.execute_reply.started":"2025-05-14T14:04:16.536151Z","shell.execute_reply":"2025-05-14T14:04:27.011226Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"data = holdout_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T14:04:27.013399Z","iopub.execute_input":"2025-05-14T14:04:27.013678Z","iopub.status.idle":"2025-05-14T14:04:27.017951Z","shell.execute_reply.started":"2025-05-14T14:04:27.013655Z","shell.execute_reply":"2025-05-14T14:04:27.017049Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# 1) Storm Prediction","metadata":{}},{"cell_type":"code","source":"# Define features\nstorm_features = [\n    'DEATHS_INDIRECT', 'INJURIES_DIRECT', 'INJURIES_INDIRECT', 'DEATHS_DIRECT',\n    'DAMAGE_PROPERTY', 'DAMAGE_CROPS', 'duration_hours',\n    'desc_word_count', 'has_tornado', 'has_hail', 'has_flood', 'has_wind',\n    'has_tree', 'has_broken', 'has_blown', 'tmin', 'tmax', 'tavg', 'ppt',\n    'MAGNITUDE_IMPUTED', 'STATE_FIPS'\n]\ntarget_col = 'is_storm_lagged'\n\n# Load storm model and scaler\nstorm_model = joblib.load('/kaggle/input/storm_xgb_model/scikitlearn/default/1/storm_xgb_model (1).pkl')\nscaler = joblib.load('/kaggle/input/storm_xgb_model/scikitlearn/default/1/storm_scaler (2).pkl')\n\n# Prepare features and scale\nX = data[storm_features].values  # Convert to NumPy array to avoid feature name warning\nX_scaled = scaler.transform(X)    # Apply scaling\n\n# Storm prediction\nstorm_preds = storm_model.predict(X_scaled)\n\n# Add predictions to DataFrame\ndata['predicted_storm'] = storm_preds\n\n# Evaluate model\ny_true = data[target_col]\ny_pred = data['predicted_storm']\naccuracy = accuracy_score(y_true, y_pred)\nprecision = precision_score(y_true, y_pred, zero_division=0)\nrecall = recall_score(y_true, y_pred, zero_division=0)\nf1 = f1_score(y_true, y_pred, zero_division=0)\nconf_matrix = confusion_matrix(y_true, y_pred)\n\nprint(\"Storm Prediction Metrics:\")\nprint(f\"Accuracy : {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall   : {recall:.4f}\")\nprint(f\"F1 Score : {f1:.4f}\")\nprint(\"\\nConfusion Matrix:\")\nprint(conf_matrix)\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_true, y_pred, zero_division=0))\n\n# Filter storm cases\nstorm_data = data[data['predicted_storm'] == 1].copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T14:04:27.018875Z","iopub.execute_input":"2025-05-14T14:04:27.019179Z","iopub.status.idle":"2025-05-14T14:04:29.003067Z","shell.execute_reply.started":"2025-05-14T14:04:27.019153Z","shell.execute_reply":"2025-05-14T14:04:29.002293Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Storm Prediction Metrics:\nAccuracy : 0.9294\nPrecision: 0.9345\nRecall   : 0.9272\nF1 Score : 0.9308\n\nConfusion Matrix:\n[[19091  1402]\n [ 1569 19993]]\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.92      0.93      0.93     20493\n           1       0.93      0.93      0.93     21562\n\n    accuracy                           0.93     42055\n   macro avg       0.93      0.93      0.93     42055\nweighted avg       0.93      0.93      0.93     42055\n\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# 2) Severity Prediction","metadata":{}},{"cell_type":"code","source":"# ----------------- SEVERITY PREDICTION -----------------\n\n# Define severity features\nseverity_features = [\n    'DEATHS_INDIRECT', 'INJURIES_DIRECT', 'INJURIES_INDIRECT', 'DEATHS_DIRECT',\n    'DAMAGE_PROPERTY', 'DAMAGE_CROPS', 'duration_hours',\n    'desc_word_count', 'has_tornado', 'has_hail', 'has_flood', 'has_wind',\n    'has_tree', 'has_broken', 'has_blown', 'tmin', 'tmax', 'tavg',\n    'EVENT_TYPE_encoded', 'stability_encoded', 'CZ_FIPS', 'WFO_encoded'\n]\ntarget_col = 'severity_class'\n\n# Load severity model and scaler\nseverity_model = joblib.load('/kaggle/input/severity_lgb_model-1/scikitlearn/default/1/severity_lgb_model (1).pkl')\nseverity_scaler = joblib.load('/kaggle/input/severity_lgb_model-1/scikitlearn/default/1/severity_scaler (3).pkl')\n\n# Prepare features and scale\nX = storm_data[severity_features].values\nX_scaled = severity_scaler.transform(X)\n\n# Severity prediction\nseverity_preds = severity_model.predict(X_scaled)\nstorm_data['predicted_severity'] = severity_preds\n\n# Evaluate severity model\ny_true = storm_data[target_col]\ny_pred = storm_data['predicted_severity']\naccuracy = accuracy_score(y_true, y_pred)\nprecision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\nrecall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\nf1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\nconf_matrix = confusion_matrix(y_true, y_pred)\n\nprint(\"Severity Prediction Metrics:\")\nprint(f\"Accuracy : {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall   : {recall:.4f}\")\nprint(f\"F1 Score : {f1:.4f}\")\nprint(\"\\nConfusion Matrix:\")\nprint(conf_matrix)\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_true, y_pred, zero_division=0))\n\n# Filter severity cases\nlow_severity_data = storm_data[storm_data['predicted_severity'] == 0].copy()\nmed_severity_data = storm_data[storm_data['predicted_severity'] == 1].copy()\nhigh_severity_data = storm_data[storm_data['predicted_severity'] == 2].copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T14:04:29.005414Z","iopub.execute_input":"2025-05-14T14:04:29.005653Z","iopub.status.idle":"2025-05-14T14:04:40.572217Z","shell.execute_reply.started":"2025-05-14T14:04:29.005635Z","shell.execute_reply":"2025-05-14T14:04:40.571265Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Severity Prediction Metrics:\nAccuracy : 0.9328\nPrecision: 0.9330\nRecall   : 0.9328\nF1 Score : 0.9329\n\nConfusion Matrix:\n[[6437  151   86    0]\n [ 127 5667  526    0]\n [  63  478 6073    0]\n [   5    0    1 1781]]\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.97      0.96      0.97      6674\n           1       0.90      0.90      0.90      6320\n           2       0.91      0.92      0.91      6614\n          10       1.00      1.00      1.00      1787\n\n    accuracy                           0.93     21395\n   macro avg       0.94      0.94      0.94     21395\nweighted avg       0.93      0.93      0.93     21395\n\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# 3) Outage Prediction","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\n# Derive is_outage target (assuming customers_out > 0 indicates an outage)\nfor df in [low_severity_data, med_severity_data, high_severity_data]:\n    df['is_outage'] = (df['customers_out'] > 0).astype(int)\n\n# Extract non-storm rows from storm_df_with_predictions\nnon_storm_data = data[data['predicted_storm'] == 0].copy()\nnon_storm_data['is_outage'] = 0  # No outage for non-storm events\nnon_storm_data['predicted_severity'] = 10  # Placeholder for non-storm rows\n\n# Randomly split non-storm rows across the three DataFrames\nnon_storm_split = np.array_split(non_storm_data.sample(frac=1, random_state=42), 3)\nnon_storm_low, non_storm_medium, non_storm_high = non_storm_split\n\n# Augment DataFrames with non-storm rows\nlow_severity_data = pd.concat([low_severity_data, non_storm_low], ignore_index=True)\nmed_severity_data = pd.concat([med_severity_data, non_storm_medium], ignore_index=True)\nhigh_severity_data = pd.concat([high_severity_data, non_storm_high], ignore_index=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T14:04:40.573129Z","iopub.execute_input":"2025-05-14T14:04:40.573766Z","iopub.status.idle":"2025-05-14T14:04:40.672583Z","shell.execute_reply.started":"2025-05-14T14:04:40.573736Z","shell.execute_reply":"2025-05-14T14:04:40.671644Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n  return bound(*args, **kwds)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"outage_features = [\n    'tmin', 'tmax', 'tavg', 'stability_encoded',\n    'EVENT_TYPE_encoded', 'duration_hours', 'desc_word_count',\n    'has_tornado', 'has_hail', 'has_flood', 'has_wind', 'has_tree',\n    'has_broken', 'has_blown', 'DAMAGE_PROPERTY', 'DAMAGE_CROPS',\n    'INJURIES_DIRECT', 'DEATHS_DIRECT', 'CZ_FIPS'\n]\ntarget_col = 'is_outage'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T14:04:40.673536Z","iopub.execute_input":"2025-05-14T14:04:40.673847Z","iopub.status.idle":"2025-05-14T14:04:40.678264Z","shell.execute_reply.started":"2025-05-14T14:04:40.673821Z","shell.execute_reply":"2025-05-14T14:04:40.677441Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"### a. Low","metadata":{}},{"cell_type":"code","source":"import joblib\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n\n# ----------------- LOAD MODEL AND SCALER -----------------\noutage_model = joblib.load('/kaggle/input/low_severity_lgm_model-1/scikitlearn/default/1/low_severity_lgm_model (1).pkl')\nscaler = joblib.load('/kaggle/input/low_severity_lgm_model-1/scikitlearn/default/1/low_severity_scaler (3).pkl')\n\n# ----------------- PREPARE FEATURES -----------------\nX = low_severity_data[outage_features]\n\n# ----------------- SCALE FEATURES -----------------\nX_scaled = scaler.transform(X)\n\n# ----------------- SEVERITY PREDICTION -----------------\noutage_pred = outage_model.predict(X_scaled)\n\n# ----------------- TRUE AND PREDICTED LABELS -----------------\ntarget_col = 'is_outage'  # Assuming this is the target column based on prior context\ny_true_outage = low_severity_data[target_col]\ny_pred_outage = outage_pred\n\n# ----------------- METRIC CALCULATIONS -----------------\naccuracy = accuracy_score(y_true_outage, y_pred_outage)\nprecision = precision_score(y_true_outage, y_pred_outage, average='binary', zero_division=0)\nrecall = recall_score(y_true_outage, y_pred_outage, average='binary', zero_division=0)\nf1 = f1_score(y_true_outage, y_pred_outage, average='binary', zero_division=0)\nconf_matrix = confusion_matrix(y_true_outage, y_pred_outage)\n\n# ----------------- OUTPUT -----------------\nprint(\"Outage Prediction Metrics:\")\nprint(f\"Accuracy : {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall   : {recall:.4f}\")\nprint(f\"F1 Score : {f1:.4f}\")\nprint(\"\\nConfusion Matrix:\")\nprint(conf_matrix)\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_true_outage, y_pred_outage, zero_division=0))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T14:04:40.679178Z","iopub.execute_input":"2025-05-14T14:04:40.679516Z","iopub.status.idle":"2025-05-14T14:04:41.418309Z","shell.execute_reply.started":"2025-05-14T14:04:40.679495Z","shell.execute_reply":"2025-05-14T14:04:41.417476Z"}},"outputs":[{"name":"stdout","text":"Outage Prediction Metrics:\nAccuracy : 0.9879\nPrecision: 0.9799\nRecall   : 0.9958\nF1 Score : 0.9878\n\nConfusion Matrix:\n[[6781  135]\n [  28 6575]]\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      0.98      0.99      6916\n           1       0.98      1.00      0.99      6603\n\n    accuracy                           0.99     13519\n   macro avg       0.99      0.99      0.99     13519\nweighted avg       0.99      0.99      0.99     13519\n\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"### b. Medium","metadata":{}},{"cell_type":"code","source":"import joblib\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n\n# ----------------- LOAD MODEL AND SCALER -----------------\noutage_model = joblib.load('/kaggle/input/medium_severity_xgb_model/scikitlearn/default/1/medium_severity_xgb_model.pkl')\nscaler = joblib.load('/kaggle/input/medium_severity_xgb_model/scikitlearn/default/1/medium_severity_scaler (1).pkl')\n\n# ----------------- PREPARE FEATURES -----------------\nX = med_severity_data[outage_features]\n\n# ----------------- SCALE FEATURES -----------------\nX_scaled = scaler.transform(X)\n\n# ----------------- SEVERITY PREDICTION -----------------\noutage_pred = outage_model.predict(X_scaled)\n\n# ----------------- TRUE AND PREDICTED LABELS -----------------\ntarget_col = 'is_outage'  # Assuming this is the target column based on prior context\ny_true_outage = med_severity_data[target_col]\ny_pred_outage = outage_pred\n\n# ----------------- METRIC CALCULATIONS -----------------\naccuracy = accuracy_score(y_true_outage, y_pred_outage)\nprecision = precision_score(y_true_outage, y_pred_outage, average='binary', zero_division=0)\nrecall = recall_score(y_true_outage, y_pred_outage, average='binary', zero_division=0)\nf1 = f1_score(y_true_outage, y_pred_outage, average='binary', zero_division=0)\nconf_matrix = confusion_matrix(y_true_outage, y_pred_outage)\n\n# ----------------- OUTPUT -----------------\nprint(\"Outage Prediction Metrics:\")\nprint(f\"Accuracy : {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall   : {recall:.4f}\")\nprint(f\"F1 Score : {f1:.4f}\")\nprint(\"\\nConfusion Matrix:\")\nprint(conf_matrix)\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_true_outage, y_pred_outage, zero_division=0))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T14:04:41.419227Z","iopub.execute_input":"2025-05-14T14:04:41.419573Z","iopub.status.idle":"2025-05-14T14:04:41.668177Z","shell.execute_reply.started":"2025-05-14T14:04:41.419545Z","shell.execute_reply":"2025-05-14T14:04:41.667284Z"}},"outputs":[{"name":"stdout","text":"Outage Prediction Metrics:\nAccuracy : 0.9747\nPrecision: 0.9587\nRecall   : 0.9897\nF1 Score : 0.9739\n\nConfusion Matrix:\n[[6630  268]\n [  65 6220]]\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.99      0.96      0.98      6898\n           1       0.96      0.99      0.97      6285\n\n    accuracy                           0.97     13183\n   macro avg       0.97      0.98      0.97     13183\nweighted avg       0.98      0.97      0.97     13183\n\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"### c. High","metadata":{}},{"cell_type":"code","source":"import joblib\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n\n# ----------------- LOAD MODEL AND SCALER -----------------\noutage_model = joblib.load('/kaggle/input/high_severity_rf_model-2/scikitlearn/default/1/high_severity_rf_model (2).pkl')\nscaler = joblib.load('/kaggle/input/high_severity_rf_model-2/scikitlearn/default/1/high_severity_scaler (2).pkl')\n\n# ----------------- PREPARE FEATURES -----------------\nX = high_severity_data[outage_features]\n\n# ----------------- SCALE FEATURES -----------------\nX_scaled = scaler.transform(X)\n\n# ----------------- SEVERITY PREDICTION -----------------\noutage_pred = outage_model.predict(X_scaled)\n\n# ----------------- TRUE AND PREDICTED LABELS -----------------\ntarget_col = 'is_outage'  # Assuming this is the target column based on prior context\ny_true_outage = high_severity_data[target_col]\ny_pred_outage = outage_pred\n\n# ----------------- METRIC CALCULATIONS -----------------\naccuracy = accuracy_score(y_true_outage, y_pred_outage)\nprecision = precision_score(y_true_outage, y_pred_outage, average='binary', zero_division=0)\nrecall = recall_score(y_true_outage, y_pred_outage, average='binary', zero_division=0)\nf1 = f1_score(y_true_outage, y_pred_outage, average='binary', zero_division=0)\nconf_matrix = confusion_matrix(y_true_outage, y_pred_outage)\n\n# ----------------- OUTPUT -----------------\nprint(\"Outage Prediction Metrics (High Severity):\")\nprint(f\"Accuracy : {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall   : {recall:.4f}\")\nprint(f\"F1 Score : {f1:.4f}\")\nprint(\"\\nConfusion Matrix:\")\nprint(conf_matrix)\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_true_outage, y_pred_outage, zero_division=0))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T14:04:41.669149Z","iopub.execute_input":"2025-05-14T14:04:41.669427Z","iopub.status.idle":"2025-05-14T14:04:42.610702Z","shell.execute_reply.started":"2025-05-14T14:04:41.669398Z","shell.execute_reply":"2025-05-14T14:04:42.609707Z"}},"outputs":[{"name":"stdout","text":"Outage Prediction Metrics (High Severity):\nAccuracy : 0.9757\nPrecision: 0.9640\nRecall   : 0.9874\nF1 Score : 0.9755\n\nConfusion Matrix:\n[[6664  246]\n [  84 6578]]\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.99      0.96      0.98      6910\n           1       0.96      0.99      0.98      6662\n\n    accuracy                           0.98     13572\n   macro avg       0.98      0.98      0.98     13572\nweighted avg       0.98      0.98      0.98     13572\n\n","output_type":"stream"}],"execution_count":9}]}