{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11641464,"sourceType":"datasetVersion","datasetId":7304854}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport joblib\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n\n# Load data\ntrain_data = pd.read_csv('/kaggle/input/mlpr-data-split/train.csv')\ntest_data = pd.read_csv('/kaggle/input/mlpr-data-split/test.csv')\nholdout_data = pd.read_csv('/kaggle/input/mlpr-data-split/holdout.csv')\n\n# Combine datasets for consistent encoding\ndata = pd.concat([train_data, test_data, holdout_data], ignore_index=True)\n\n# Encoding using DAMAGE_PROPERTY (numerical, non-target variable)\ncategorical_cols = ['EVENT_TYPE', 'stability', 'WFO']\nencoding_maps = {}\n\n# Compute encoding mappings from training data using DAMAGE_PROPERTY\nfor col in categorical_cols:\n    if col in train_data.columns:\n        encoding_maps[col] = train_data.groupby(col)['ppt'].mean() \n\n# Apply encoding to combined data\nfor col in categorical_cols:\n    if col in data.columns:\n        data[col + '_encoded'] = data[col].map(encoding_maps[col]).fillna(train_data['ppt'].mean())\n\n# Split back into train, test, holdout\ntrain_data = data.iloc[:len(train_data)]\ntest_data = data.iloc[len(train_data):len(train_data) + len(test_data)]\nholdout_data = data.iloc[len(train_data) + len(test_data):]","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-14T19:33:53.594840Z","iopub.execute_input":"2025-05-14T19:33:53.595123Z","iopub.status.idle":"2025-05-14T19:34:05.833224Z","shell.execute_reply.started":"2025-05-14T19:33:53.595096Z","shell.execute_reply":"2025-05-14T19:34:05.832340Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport joblib\nimport lightgbm as lgb\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n\n# Filter for storm events\ntrain_data = train_data[train_data['is_storm_lagged'] == 1]\ntest_data = test_data[test_data['is_storm_lagged'] == 1]\n\n# Define features and target\nseverity_features = [\n    'DEATHS_INDIRECT', 'INJURIES_DIRECT', 'INJURIES_INDIRECT', 'DEATHS_DIRECT',\n    'DAMAGE_PROPERTY', 'DAMAGE_CROPS', 'duration_hours',\n    'desc_word_count', 'has_tornado', 'has_hail', 'has_flood', 'has_wind',\n    'has_tree', 'has_broken', 'has_blown', 'tmin', 'tmax', 'tavg',\n    'EVENT_TYPE_encoded', 'stability_encoded', 'CZ_FIPS', 'WFO_encoded'\n]\ntarget_col = 'severity_class'\n\n# Prepare training features and target\nX_train = train_data[severity_features]\ny_train = train_data[target_col]\n\n# Scale training features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\n\n# Prepare test features and target\nX_test = test_data[severity_features]\ny_test = test_data[target_col]\nX_test_scaled = scaler.transform(X_test)\n\n# Use best parameters found via Optuna\nfinal_params = {\n    'objective': 'multiclass',\n    'num_class': len(y_train.unique()),\n    'metric': 'multi_logloss',\n    'boosting_type': 'gbdt',\n    'verbose': -1,\n    'random_state': 42,\n    'n_estimators': 943,\n    'max_depth': 14,\n    'learning_rate': 0.299798636793099,\n    'subsample': 0.6815843772645557,\n    'colsample_bytree': 0.967548003596196,\n    'min_child_weight': 1.2892385914567714,\n    'reg_alpha': 0.009927790289736168,\n    'reg_lambda': 1.7396121269192825e-06\n}\n\n# Train final LightGBM model\nlgb_model = lgb.LGBMClassifier(**final_params)\nlgb_model.fit(X_train_scaled, y_train)\n\n# Evaluate model on test data\ny_pred = lgb_model.predict(X_test_scaled)\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\nrecall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\nf1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\nconf_matrix = confusion_matrix(y_test, y_pred)\n\nprint(\"Severity Prediction Test Metrics (LightGBM):\")\nprint(f\"Accuracy : {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall   : {recall:.4f}\")\nprint(f\"F1 Score : {f1:.4f}\")\nprint(\"\\nConfusion Matrix:\")\nprint(conf_matrix)\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred, zero_division=0))\n\n# Save the model and scaler\njoblib.dump(lgb_model, 'severity_lgb_model.pkl')\njoblib.dump(scaler, 'severity_scaler.pkl')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T19:34:40.268307Z","iopub.execute_input":"2025-05-14T19:34:40.269387Z","iopub.status.idle":"2025-05-14T19:35:02.363702Z","shell.execute_reply.started":"2025-05-14T19:34:40.269351Z","shell.execute_reply":"2025-05-14T19:35:02.362969Z"}},"outputs":[{"name":"stdout","text":"Severity Prediction Test Metrics (LightGBM):\nAccuracy : 0.9308\nPrecision: 0.9309\nRecall   : 0.9308\nF1 Score : 0.9308\n\nConfusion Matrix:\n[[3109   73   53    0]\n [  76 2698  257    0]\n [  32  239 2881    0]\n [   2    0    0 1152]]\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.97      0.96      0.96      3235\n           1       0.90      0.89      0.89      3031\n           2       0.90      0.91      0.91      3152\n          10       1.00      1.00      1.00      1154\n\n    accuracy                           0.93     10572\n   macro avg       0.94      0.94      0.94     10572\nweighted avg       0.93      0.93      0.93     10572\n\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"['severity_scaler.pkl']"},"metadata":{}}],"execution_count":2}]}