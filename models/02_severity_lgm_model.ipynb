{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T21:06:58.230433Z",
     "iopub.status.busy": "2025-05-13T21:06:58.230050Z",
     "iopub.status.idle": "2025-05-13T21:07:19.175070Z",
     "shell.execute_reply": "2025-05-13T21:07:19.174155Z",
     "shell.execute_reply.started": "2025-05-13T21:06:58.230404Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Severity Prediction Test Metrics:\n",
      "Accuracy : 0.9998\n",
      "Precision: 0.9998\n",
      "Recall   : 0.9998\n",
      "F1 Score : 0.9998\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3235    0    0    0]\n",
      " [   1 3030    0    0]\n",
      " [   0    0 3152    0]\n",
      " [   1    0    0 1153]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3235\n",
      "           1       1.00      1.00      1.00      3031\n",
      "           2       1.00      1.00      1.00      3152\n",
      "          10       1.00      1.00      1.00      1154\n",
      "\n",
      "    accuracy                           1.00     10572\n",
      "   macro avg       1.00      1.00      1.00     10572\n",
      "weighted avg       1.00      1.00      1.00     10572\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['severity_scaler.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# Load training and test data\n",
    "train_data = pd.read_csv('/kaggle/input/mlpr-data-split/train.csv')\n",
    "test_data = pd.read_csv('/kaggle/input/mlpr-data-split/test.csv')\n",
    "\n",
    "# Filter for storm events\n",
    "train_data = train_data[train_data['is_storm_lagged'] == 1]\n",
    "test_data = test_data[test_data['is_storm_lagged'] == 1]\n",
    "\n",
    "severity_features = [\n",
    "    'DEATHS_INDIRECT', 'INJURIES_DIRECT', 'INJURIES_INDIRECT', 'DEATHS_DIRECT',\n",
    "    'DAMAGE_PROPERTY', 'DAMAGE_CROPS', 'duration_hours',\n",
    "    'desc_word_count', 'has_tornado', 'has_hail', 'has_flood', 'has_wind',\n",
    "    'has_tree', 'has_broken', 'has_blown', 'tmin', 'tmax', 'tavg', 'ppt',\n",
    "    'MAGNITUDE_IMPUTED', 'CZ_FIPS'\n",
    "]\n",
    "target_col = 'severity_class'\n",
    "\n",
    "# Prepare training features and target\n",
    "X_train = train_data[severity_features]\n",
    "y_train = train_data[target_col]\n",
    "\n",
    "# Scale training features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Initialize and train model\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=201,\n",
    "    max_depth=38,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42\n",
    ")\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prepare test features and target\n",
    "X_test = test_data[severity_features]\n",
    "y_test = test_data[target_col]\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Evaluate model on test data\n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Severity Prediction Test Metrics:\")\n",
    "print(f\"Accuracy : {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall   : {recall:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Save the model and scaler\n",
    "joblib.dump(rf_model, 'severity_rf_model.pkl')\n",
    "joblib.dump(scaler, 'severity_scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T21:16:07.640728Z",
     "iopub.status.busy": "2025-05-13T21:16:07.640320Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# Load training and test data\n",
    "train_data = pd.read_csv('/kaggle/input/mlpr-data-split/train.csv')\n",
    "test_data = pd.read_csv('/kaggle/input/mlpr-data-split/test.csv')\n",
    "\n",
    "# Filter for storm events\n",
    "train_data = train_data[train_data['is_storm_lagged'] == 1]\n",
    "test_data = test_data[test_data['is_storm_lagged'] == 1]\n",
    "\n",
    "# Define valid severity classes\n",
    "valid_classes = [0, 1, 2, 3]\n",
    "\n",
    "# Filter out invalid severity_class values\n",
    "train_data = train_data[train_data['severity_class'].isin(valid_classes)]\n",
    "test_data = test_data[test_data['severity_class'].isin(valid_classes)]\n",
    "\n",
    "# Define features and target\n",
    "severity_features = [\n",
    "    'DEATHS_INDIRECT', 'INJURIES_DIRECT', 'INJURIES_INDIRECT', 'DEATHS_DIRECT',\n",
    "    'DAMAGE_PROPERTY', 'DAMAGE_CROPS', 'duration_hours',\n",
    "    'desc_word_count', 'has_tornado', 'has_hail', 'has_flood', 'has_wind',\n",
    "    'has_tree', 'has_broken', 'has_blown', 'tmin', 'tmax', 'tavg', 'ppt',\n",
    "    'MAGNITUDE_IMPUTED', 'CZ_FIPS'\n",
    "]\n",
    "target_col = 'severity_class'\n",
    "\n",
    "# Prepare training features and target\n",
    "X_train = train_data[severity_features]\n",
    "y_train = train_data[target_col]\n",
    "\n",
    "# Scale training features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Initialize and train model\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=403,\n",
    "    max_depth=10,\n",
    "    learning_rate=0.09065400280278058,\n",
    "    subsample=0.933968095670629,\n",
    "    colsample_bytree=0.5647574078202744,\n",
    "    gamma=0.00017586655077512627,\n",
    "    min_child_weight=2,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prepare test features and target\n",
    "X_test = test_data[severity_features]\n",
    "y_test = test_data[target_col]\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Evaluate model on test data\n",
    "y_pred = xgb_model.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Severity Prediction Test Metrics:\")\n",
    "print(f\"Accuracy : {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall   : {recall:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Optionally save the model and scaler\n",
    "# joblib.dump(xgb_model, 'severity_xg_model.pkl')\n",
    "# joblib.dump(scaler, 'severity_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T18:05:58.644893Z",
     "iopub.status.busy": "2025-05-13T18:05:58.644580Z",
     "iopub.status.idle": "2025-05-13T18:19:13.622708Z",
     "shell.execute_reply": "2025-05-13T18:19:13.621598Z",
     "shell.execute_reply.started": "2025-05-13T18:05:58.644871Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-13 18:06:03,188] A new study created in memory with name: no-name-d9795be3-ddca-412b-a599-0021637c9d60\n",
      "[I 2025-05-13 18:06:23,305] Trial 0 finished with value: 0.6571131290200529 and parameters: {'n_estimators': 844, 'max_depth': 14, 'learning_rate': 0.016419063074686612, 'subsample': 0.8414746347199225, 'colsample_bytree': 0.9287190128546008, 'min_child_weight': 0.0019491484745080127, 'reg_alpha': 0.16012974705799382, 'reg_lambda': 0.003258151609977881}. Best is trial 0 with value: 0.6571131290200529.\n",
      "[I 2025-05-13 18:06:38,096] Trial 1 finished with value: 0.6128452516080212 and parameters: {'n_estimators': 595, 'max_depth': 9, 'learning_rate': 0.013713452744354855, 'subsample': 0.9408418339243743, 'colsample_bytree': 0.9095841493007747, 'min_child_weight': 0.0011637895424480662, 'reg_alpha': 0.011690821662610389, 'reg_lambda': 0.08411409054769989}. Best is trial 0 with value: 0.6571131290200529.\n",
      "[I 2025-05-13 18:06:48,500] Trial 2 finished with value: 0.7948354143019296 and parameters: {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.16991115091574366, 'subsample': 0.542017245807731, 'colsample_bytree': 0.7252098580171271, 'min_child_weight': 1.8144695341979067, 'reg_alpha': 7.233993509880907e-08, 'reg_lambda': 1.4710102618719938}. Best is trial 2 with value: 0.7948354143019296.\n",
      "[I 2025-05-13 18:06:55,582] Trial 3 finished with value: 0.6153045781309119 and parameters: {'n_estimators': 260, 'max_depth': 7, 'learning_rate': 0.04110221182359749, 'subsample': 0.6203167189538896, 'colsample_bytree': 0.9382638127388794, 'min_child_weight': 5.762192379511158, 'reg_alpha': 0.0011136774763429872, 'reg_lambda': 9.76170063779606}. Best is trial 2 with value: 0.7948354143019296.\n",
      "[I 2025-05-13 18:07:02,916] Trial 4 finished with value: 0.5636587211502081 and parameters: {'n_estimators': 230, 'max_depth': 10, 'learning_rate': 0.012746506048858334, 'subsample': 0.9961452294481261, 'colsample_bytree': 0.5149386677156356, 'min_child_weight': 0.5915793379398337, 'reg_alpha': 0.3449064431468191, 'reg_lambda': 0.00015809137130748423}. Best is trial 2 with value: 0.7948354143019296.\n",
      "[I 2025-05-13 18:07:12,393] Trial 5 finished with value: 0.68946273174423 and parameters: {'n_estimators': 670, 'max_depth': 3, 'learning_rate': 0.2909333834622564, 'subsample': 0.8080436015451653, 'colsample_bytree': 0.7499247297399474, 'min_child_weight': 4.14901403862739, 'reg_alpha': 3.2676467291484353e-05, 'reg_lambda': 5.7800161624526516e-06}. Best is trial 2 with value: 0.7948354143019296.\n",
      "[I 2025-05-13 18:07:33,150] Trial 6 finished with value: 0.7280552402572834 and parameters: {'n_estimators': 885, 'max_depth': 9, 'learning_rate': 0.03606589899227381, 'subsample': 0.9119588435881203, 'colsample_bytree': 0.8301392324553845, 'min_child_weight': 0.1749078040458081, 'reg_alpha': 0.1766563812450338, 'reg_lambda': 0.5711807894912267}. Best is trial 2 with value: 0.7948354143019296.\n",
      "[I 2025-05-13 18:07:41,062] Trial 7 finished with value: 0.7458380628074158 and parameters: {'n_estimators': 372, 'max_depth': 11, 'learning_rate': 0.10347494178872037, 'subsample': 0.7384787574314359, 'colsample_bytree': 0.7546334900446752, 'min_child_weight': 0.22501796028296628, 'reg_alpha': 8.289423619589175e-06, 'reg_lambda': 1.0225097153971447e-06}. Best is trial 2 with value: 0.7948354143019296.\n",
      "[I 2025-05-13 18:07:47,419] Trial 8 finished with value: 0.7949300037835793 and parameters: {'n_estimators': 313, 'max_depth': 14, 'learning_rate': 0.22367955932300623, 'subsample': 0.5570027007193105, 'colsample_bytree': 0.917335132546518, 'min_child_weight': 0.01697322490535125, 'reg_alpha': 0.0005613321766503769, 'reg_lambda': 0.14202238976888995}. Best is trial 8 with value: 0.7949300037835793.\n",
      "[I 2025-05-13 18:07:52,949] Trial 9 finished with value: 0.6732879303821415 and parameters: {'n_estimators': 228, 'max_depth': 15, 'learning_rate': 0.0715451945229121, 'subsample': 0.8675377263479, 'colsample_bytree': 0.9053850071916737, 'min_child_weight': 7.603260451243683, 'reg_alpha': 0.10255543305821678, 'reg_lambda': 0.07901233656351127}. Best is trial 8 with value: 0.7949300037835793.\n",
      "[I 2025-05-13 18:08:03,547] Trial 10 finished with value: 0.8136587211502081 and parameters: {'n_estimators': 419, 'max_depth': 13, 'learning_rate': 0.25156740948913486, 'subsample': 0.5088485267175469, 'colsample_bytree': 0.5866304684846091, 'min_child_weight': 0.017309355762054057, 'reg_alpha': 1.1318735952773946e-07, 'reg_lambda': 5.2548537296938594e-08}. Best is trial 10 with value: 0.8136587211502081.\n",
      "[I 2025-05-13 18:08:13,284] Trial 11 finished with value: 0.7999432463110102 and parameters: {'n_estimators': 416, 'max_depth': 13, 'learning_rate': 0.20239669690455311, 'subsample': 0.507584410614972, 'colsample_bytree': 0.5642455511184687, 'min_child_weight': 0.018751050001365937, 'reg_alpha': 7.079529633080898e-08, 'reg_lambda': 4.025214670019225e-08}. Best is trial 10 with value: 0.8136587211502081.\n",
      "[I 2025-05-13 18:08:16,150] Trial 12 finished with value: 0.6519107075293228 and parameters: {'n_estimators': 104, 'max_depth': 12, 'learning_rate': 0.13301190099527097, 'subsample': 0.6602297404738675, 'colsample_bytree': 0.5373224440755492, 'min_child_weight': 0.01684892374577435, 'reg_alpha': 1.4240758363874244e-08, 'reg_lambda': 1.8254958240060328e-08}. Best is trial 10 with value: 0.8136587211502081.\n",
      "[I 2025-05-13 18:08:28,053] Trial 13 finished with value: 0.7566212637154749 and parameters: {'n_estimators': 506, 'max_depth': 12, 'learning_rate': 0.0863593547348795, 'subsample': 0.5168892037193931, 'colsample_bytree': 0.6133242848407339, 'min_child_weight': 0.018986965504886225, 'reg_alpha': 7.810709223423066e-07, 'reg_lambda': 4.1377933628356685e-08}. Best is trial 10 with value: 0.8136587211502081.\n",
      "[I 2025-05-13 18:08:39,051] Trial 14 finished with value: 0.772890654559213 and parameters: {'n_estimators': 417, 'max_depth': 13, 'learning_rate': 0.2881772730505507, 'subsample': 0.6264181665025657, 'colsample_bytree': 0.5996772975157051, 'min_child_weight': 0.005823000459208283, 'reg_alpha': 8.525047921020978, 'reg_lambda': 6.175392287467911e-07}. Best is trial 10 with value: 0.8136587211502081.\n",
      "[I 2025-05-13 18:08:55,080] Trial 15 finished with value: 0.8108210367007189 and parameters: {'n_estimators': 717, 'max_depth': 6, 'learning_rate': 0.16669410813158797, 'subsample': 0.7135120716423305, 'colsample_bytree': 0.6455182870605928, 'min_child_weight': 0.05967929997470166, 'reg_alpha': 1.1237323410181282e-06, 'reg_lambda': 5.222319188649134e-05}. Best is trial 10 with value: 0.8136587211502081.\n",
      "[I 2025-05-13 18:09:10,718] Trial 16 finished with value: 0.7797956867196367 and parameters: {'n_estimators': 711, 'max_depth': 5, 'learning_rate': 0.13879610434148673, 'subsample': 0.7296569778542893, 'colsample_bytree': 0.6604101219284841, 'min_child_weight': 0.07015893936901839, 'reg_alpha': 2.72718524763109e-06, 'reg_lambda': 6.850963492393736e-05}. Best is trial 10 with value: 0.8136587211502081.\n",
      "[I 2025-05-13 18:09:32,098] Trial 17 finished with value: 0.7492432841468029 and parameters: {'n_estimators': 973, 'max_depth': 6, 'learning_rate': 0.05195902290276257, 'subsample': 0.6817581017032158, 'colsample_bytree': 0.669913320418633, 'min_child_weight': 0.05943212052352217, 'reg_alpha': 4.756833861800303e-07, 'reg_lambda': 0.0020067774500803466}. Best is trial 10 with value: 0.8136587211502081.\n",
      "[I 2025-05-13 18:09:46,106] Trial 18 finished with value: 0.5851305334846765 and parameters: {'n_estimators': 739, 'max_depth': 4, 'learning_rate': 0.02522137417474455, 'subsample': 0.585485959407705, 'colsample_bytree': 0.6590494081361706, 'min_child_weight': 0.00414935874022835, 'reg_alpha': 6.606001375028134e-05, 'reg_lambda': 9.794685472188278e-06}. Best is trial 10 with value: 0.8136587211502081.\n",
      "[I 2025-05-13 18:09:57,010] Trial 19 finished with value: 0.7782822550132426 and parameters: {'n_estimators': 548, 'max_depth': 7, 'learning_rate': 0.12163909979596316, 'subsample': 0.7817826552723951, 'colsample_bytree': 0.8219870910657214, 'min_child_weight': 0.6006500357690601, 'reg_alpha': 2.108676189262214e-07, 'reg_lambda': 2.9947825605876027e-07}. Best is trial 10 with value: 0.8136587211502081.\n",
      "[I 2025-05-13 18:10:11,918] Trial 20 finished with value: 0.7075293227393114 and parameters: {'n_estimators': 636, 'max_depth': 5, 'learning_rate': 0.06751920344139908, 'subsample': 0.6998537305699535, 'colsample_bytree': 0.6201071675188063, 'min_child_weight': 0.038462355536914725, 'reg_alpha': 1.6237878636725533e-08, 'reg_lambda': 0.0009730387212873564}. Best is trial 10 with value: 0.8136587211502081.\n",
      "[I 2025-05-13 18:10:22,014] Trial 21 finished with value: 0.7988081725312145 and parameters: {'n_estimators': 434, 'max_depth': 11, 'learning_rate': 0.18619159787359837, 'subsample': 0.5053994727570337, 'colsample_bytree': 0.5638014970640791, 'min_child_weight': 0.0070225189964385724, 'reg_alpha': 1.0637254477998871e-07, 'reg_lambda': 7.898997341240192e-08}. Best is trial 10 with value: 0.8136587211502081.\n",
      "[I 2025-05-13 18:10:41,031] Trial 22 finished with value: 0.8359818388195233 and parameters: {'n_estimators': 815, 'max_depth': 15, 'learning_rate': 0.19031033674378267, 'subsample': 0.5887489117515551, 'colsample_bytree': 0.5923082471984207, 'min_child_weight': 0.0278532518302833, 'reg_alpha': 4.187327777404411e-06, 'reg_lambda': 9.709095162579144e-06}. Best is trial 22 with value: 0.8359818388195233.\n",
      "[I 2025-05-13 18:10:56,738] Trial 23 finished with value: 0.848940597805524 and parameters: {'n_estimators': 813, 'max_depth': 15, 'learning_rate': 0.22618395365717092, 'subsample': 0.5881851179426604, 'colsample_bytree': 0.998617460596896, 'min_child_weight': 0.14183663841404393, 'reg_alpha': 4.517716060972245e-06, 'reg_lambda': 1.7267107004029737e-05}. Best is trial 23 with value: 0.848940597805524.\n",
      "[I 2025-05-13 18:11:12,670] Trial 24 finished with value: 0.8494135452137722 and parameters: {'n_estimators': 803, 'max_depth': 15, 'learning_rate': 0.2407313415195679, 'subsample': 0.5874073245867015, 'colsample_bytree': 0.990205261589002, 'min_child_weight': 0.15958858848792495, 'reg_alpha': 1.2792042988309354e-05, 'reg_lambda': 2.451961644907005e-06}. Best is trial 24 with value: 0.8494135452137722.\n",
      "[I 2025-05-13 18:11:28,952] Trial 25 finished with value: 0.8106318577374196 and parameters: {'n_estimators': 820, 'max_depth': 15, 'learning_rate': 0.10292517730387912, 'subsample': 0.5983096465769582, 'colsample_bytree': 0.9632698956673381, 'min_child_weight': 0.1798380575780258, 'reg_alpha': 1.4257841257502388e-05, 'reg_lambda': 7.149283084422898e-06}. Best is trial 24 with value: 0.8494135452137722.\n",
      "[I 2025-05-13 18:11:48,830] Trial 26 finished with value: 0.8548997351494514 and parameters: {'n_estimators': 1000, 'max_depth': 15, 'learning_rate': 0.22378005662403253, 'subsample': 0.6484547130958941, 'colsample_bytree': 0.998537989051165, 'min_child_weight': 0.5129171222103419, 'reg_alpha': 0.00011112869596990523, 'reg_lambda': 2.161127020243338e-05}. Best is trial 26 with value: 0.8548997351494514.\n",
      "[I 2025-05-13 18:12:07,590] Trial 27 finished with value: 0.8535754824063564 and parameters: {'n_estimators': 976, 'max_depth': 14, 'learning_rate': 0.23527723814079862, 'subsample': 0.6518751961771756, 'colsample_bytree': 0.9712237358612636, 'min_child_weight': 0.5659019204455216, 'reg_alpha': 0.00014186853310247112, 'reg_lambda': 1.465598635901461e-06}. Best is trial 26 with value: 0.8548997351494514.\n",
      "[I 2025-05-13 18:12:28,914] Trial 28 finished with value: 0.8337116912599319 and parameters: {'n_estimators': 998, 'max_depth': 14, 'learning_rate': 0.1344984908265542, 'subsample': 0.6459331730498332, 'colsample_bytree': 0.8742426477196169, 'min_child_weight': 0.4625193667612254, 'reg_alpha': 0.00017745050727377255, 'reg_lambda': 3.157280182024011e-07}. Best is trial 26 with value: 0.8548997351494514.\n",
      "[I 2025-05-13 18:12:46,764] Trial 29 finished with value: 0.857359061672342 and parameters: {'n_estimators': 895, 'max_depth': 14, 'learning_rate': 0.2985057390942638, 'subsample': 0.7648867961659446, 'colsample_bytree': 0.9981528163090204, 'min_child_weight': 0.350935800635874, 'reg_alpha': 0.0012034474223233198, 'reg_lambda': 2.735677071640862e-06}. Best is trial 29 with value: 0.857359061672342.\n",
      "[I 2025-05-13 18:13:07,548] Trial 30 finished with value: 0.6877601210745365 and parameters: {'n_estimators': 912, 'max_depth': 12, 'learning_rate': 0.020877436391299183, 'subsample': 0.7883929395164662, 'colsample_bytree': 0.9577506531979905, 'min_child_weight': 1.8561530086048148, 'reg_alpha': 0.0034231321201845756, 'reg_lambda': 0.007979118698967084}. Best is trial 29 with value: 0.857359061672342.\n",
      "[I 2025-05-13 18:13:26,358] Trial 31 finished with value: 0.8571698827090427 and parameters: {'n_estimators': 929, 'max_depth': 14, 'learning_rate': 0.2707577503840247, 'subsample': 0.6812184555783825, 'colsample_bytree': 0.9940404310641996, 'min_child_weight': 1.1333712213798908, 'reg_alpha': 0.00014973388931120927, 'reg_lambda': 2.0920302804267807e-06}. Best is trial 29 with value: 0.857359061672342.\n",
      "[I 2025-05-13 18:13:44,657] Trial 32 finished with value: 0.8580211880438895 and parameters: {'n_estimators': 943, 'max_depth': 14, 'learning_rate': 0.299798636793099, 'subsample': 0.6815843772645557, 'colsample_bytree': 0.967548003596196, 'min_child_weight': 1.2892385914567714, 'reg_alpha': 0.009927790289736168, 'reg_lambda': 1.7396121269192825e-06}. Best is trial 32 with value: 0.8580211880438895.\n",
      "[I 2025-05-13 18:14:03,116] Trial 33 finished with value: 0.856318577374196 and parameters: {'n_estimators': 905, 'max_depth': 13, 'learning_rate': 0.2870651877558607, 'subsample': 0.7541686455805467, 'colsample_bytree': 0.8754172244581478, 'min_child_weight': 1.8967730927157107, 'reg_alpha': 0.017942573065474924, 'reg_lambda': 5.22622074775025e-05}. Best is trial 32 with value: 0.8580211880438895.\n",
      "[I 2025-05-13 18:14:20,736] Trial 34 finished with value: 0.8535754824063564 and parameters: {'n_estimators': 909, 'max_depth': 13, 'learning_rate': 0.28623089378076466, 'subsample': 0.7593888271422289, 'colsample_bytree': 0.8692907435739889, 'min_child_weight': 1.6184671076794301, 'reg_alpha': 0.01783932508686995, 'reg_lambda': 0.00036977855336022225}. Best is trial 32 with value: 0.8580211880438895.\n",
      "[I 2025-05-13 18:14:38,599] Trial 35 finished with value: 0.8385357548240636 and parameters: {'n_estimators': 881, 'max_depth': 11, 'learning_rate': 0.16832436687204128, 'subsample': 0.8281725247441457, 'colsample_bytree': 0.9394640079240304, 'min_child_weight': 1.2282229977680634, 'reg_alpha': 0.004378618422325813, 'reg_lambda': 1.7139138584018595e-07}. Best is trial 32 with value: 0.8580211880438895.\n",
      "[I 2025-05-13 18:15:02,578] Trial 36 finished with value: 0.6286416950435112 and parameters: {'n_estimators': 928, 'max_depth': 14, 'learning_rate': 0.01026551395336968, 'subsample': 0.6927852714631539, 'colsample_bytree': 0.8859143254001081, 'min_child_weight': 3.617308542813762, 'reg_alpha': 0.031244278964767856, 'reg_lambda': 2.4874302971573374e-06}. Best is trial 32 with value: 0.8580211880438895.\n",
      "[I 2025-05-13 18:15:18,744] Trial 37 finished with value: 0.8503594400302686 and parameters: {'n_estimators': 766, 'max_depth': 10, 'learning_rate': 0.29865365985179393, 'subsample': 0.8649641923637827, 'colsample_bytree': 0.8354551372978437, 'min_child_weight': 2.870515020905492, 'reg_alpha': 0.0011909026557848802, 'reg_lambda': 0.00019858603488599256}. Best is trial 32 with value: 0.8580211880438895.\n",
      "[I 2025-05-13 18:15:38,149] Trial 38 finished with value: 0.8408059023836549 and parameters: {'n_estimators': 945, 'max_depth': 14, 'learning_rate': 0.16812130834149785, 'subsample': 0.7737457776999003, 'colsample_bytree': 0.9417902738279588, 'min_child_weight': 0.9101696518926428, 'reg_alpha': 0.876238420402113, 'reg_lambda': 5.001448188045165e-05}. Best is trial 32 with value: 0.8580211880438895.\n",
      "[I 2025-05-13 18:15:55,486] Trial 39 finished with value: 0.8531025349981082 and parameters: {'n_estimators': 856, 'max_depth': 10, 'learning_rate': 0.2987292138348106, 'subsample': 0.7464239293630128, 'colsample_bytree': 0.798419288208968, 'min_child_weight': 0.33292225067924036, 'reg_alpha': 0.004359884450941483, 'reg_lambda': 2.187516438588148e-06}. Best is trial 32 with value: 0.8580211880438895.\n",
      "[I 2025-05-13 18:16:14,757] Trial 40 finished with value: 0.729474082482028 and parameters: {'n_estimators': 862, 'max_depth': 12, 'learning_rate': 0.03405133510360566, 'subsample': 0.8179434498734612, 'colsample_bytree': 0.9027997231611773, 'min_child_weight': 2.1472754962378877, 'reg_alpha': 0.057986596399671866, 'reg_lambda': 0.006947118263249221}. Best is trial 32 with value: 0.8580211880438895.\n",
      "[I 2025-05-13 18:16:33,317] Trial 41 finished with value: 0.8568861142640938 and parameters: {'n_estimators': 957, 'max_depth': 14, 'learning_rate': 0.24803152547150412, 'subsample': 0.7147481435574394, 'colsample_bytree': 0.980947168932599, 'min_child_weight': 0.8754036117315973, 'reg_alpha': 0.0005267681059394249, 'reg_lambda': 2.469315287634689e-05}. Best is trial 32 with value: 0.8580211880438895.\n",
      "[I 2025-05-13 18:16:51,472] Trial 42 finished with value: 0.8551835035944003 and parameters: {'n_estimators': 945, 'max_depth': 13, 'learning_rate': 0.25647664370063294, 'subsample': 0.7248757205691663, 'colsample_bytree': 0.9736759949650289, 'min_child_weight': 0.8599461986466086, 'reg_alpha': 0.0009313104929667187, 'reg_lambda': 4.437850451394189e-06}. Best is trial 32 with value: 0.8580211880438895.\n",
      "[I 2025-05-13 18:17:09,765] Trial 43 finished with value: 0.8458191449110859 and parameters: {'n_estimators': 890, 'max_depth': 14, 'learning_rate': 0.19794492713634965, 'subsample': 0.6827102185159166, 'colsample_bytree': 0.9287533096621012, 'min_child_weight': 4.682806600505226, 'reg_alpha': 0.0003472100197992614, 'reg_lambda': 3.081830997207382e-05}. Best is trial 32 with value: 0.8580211880438895.\n",
      "[I 2025-05-13 18:17:26,195] Trial 44 finished with value: 0.8500756715853197 and parameters: {'n_estimators': 778, 'max_depth': 13, 'learning_rate': 0.25767876456135247, 'subsample': 0.7645962840181836, 'colsample_bytree': 0.9493402692354773, 'min_child_weight': 0.3117205617626126, 'reg_alpha': 0.002007396606000411, 'reg_lambda': 0.00011823139932849692}. Best is trial 32 with value: 0.8580211880438895.\n",
      "[I 2025-05-13 18:17:46,956] Trial 45 finished with value: 0.8353197124479758 and parameters: {'n_estimators': 954, 'max_depth': 14, 'learning_rate': 0.15076565839749265, 'subsample': 0.7106451176091445, 'colsample_bytree': 0.9804717308557546, 'min_child_weight': 7.27254811910174, 'reg_alpha': 0.25668378569937556, 'reg_lambda': 8.174228790260495e-07}. Best is trial 32 with value: 0.8580211880438895.\n",
      "[I 2025-05-13 18:18:03,451] Trial 46 finished with value: 0.8483730609156261 and parameters: {'n_estimators': 855, 'max_depth': 11, 'learning_rate': 0.20879884098677334, 'subsample': 0.8003454883880273, 'colsample_bytree': 0.9187923999103393, 'min_child_weight': 1.1564389243535156, 'reg_alpha': 0.01243622338664632, 'reg_lambda': 1.6366604821472967e-07}. Best is trial 32 with value: 0.8580211880438895.\n",
      "[I 2025-05-13 18:18:17,435] Trial 47 finished with value: 0.8401437760121074 and parameters: {'n_estimators': 641, 'max_depth': 12, 'learning_rate': 0.2580459410780429, 'subsample': 0.6726962024493134, 'colsample_bytree': 0.7067748851101334, 'min_child_weight': 2.431748839264844, 'reg_alpha': 0.0005682034439490589, 'reg_lambda': 0.0005651667332332944}. Best is trial 32 with value: 0.8580211880438895.\n",
      "[I 2025-05-13 18:18:36,469] Trial 48 finished with value: 0.8199016269390844 and parameters: {'n_estimators': 915, 'max_depth': 8, 'learning_rate': 0.11703953337493131, 'subsample': 0.9885924208221593, 'colsample_bytree': 0.8504005002901281, 'min_child_weight': 0.3260503913240993, 'reg_alpha': 3.050622549240056e-05, 'reg_lambda': 5.055294603679882e-06}. Best is trial 32 with value: 0.8580211880438895.\n",
      "[I 2025-05-13 18:18:55,374] Trial 49 finished with value: 0.8165909950813469 and parameters: {'n_estimators': 840, 'max_depth': 13, 'learning_rate': 0.1533220187435756, 'subsample': 0.7470237621682739, 'colsample_bytree': 0.7734920622610693, 'min_child_weight': 0.8677217882366183, 'reg_alpha': 0.005756314952681906, 'reg_lambda': 5.356674455211098}. Best is trial 32 with value: 0.8580211880438895.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_estimators': 943, 'max_depth': 14, 'learning_rate': 0.299798636793099, 'subsample': 0.6815843772645557, 'colsample_bytree': 0.967548003596196, 'min_child_weight': 1.2892385914567714, 'reg_alpha': 0.009927790289736168, 'reg_lambda': 1.7396121269192825e-06}\n",
      "Severity Prediction Test Metrics (LightGBM):\n",
      "Accuracy : 0.8580\n",
      "Precision: 0.8582\n",
      "Recall   : 0.8580\n",
      "F1 Score : 0.8581\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2896  156  155   28]\n",
      " [ 167 2478  336   50]\n",
      " [ 120  320 2665   47]\n",
      " [  19   42   61 1032]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90      3235\n",
      "           1       0.83      0.82      0.82      3031\n",
      "           2       0.83      0.85      0.84      3152\n",
      "          10       0.89      0.89      0.89      1154\n",
      "\n",
      "    accuracy                           0.86     10572\n",
      "   macro avg       0.86      0.86      0.86     10572\n",
      "weighted avg       0.86      0.86      0.86     10572\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# Load training and test data\n",
    "train_data = pd.read_csv('/kaggle/input/mlpr-data-split/train.csv')\n",
    "test_data = pd.read_csv('/kaggle/input/mlpr-data-split/test.csv')\n",
    "\n",
    "# Filter for storm events\n",
    "train_data = train_data[train_data['is_storm_lagged'] == 1]\n",
    "test_data = test_data[test_data['is_storm_lagged'] == 1]\n",
    "\n",
    "# Define features and target\n",
    "severity_features = [\n",
    "    'DEATHS_INDIRECT', 'INJURIES_DIRECT', 'INJURIES_INDIRECT', 'DEATHS_DIRECT',\n",
    "    'DAMAGE_PROPERTY', 'DAMAGE_CROPS', 'customers_out', 'duration_hours',\n",
    "    'desc_word_count', 'desc_char_count',\n",
    "    'has_tornado', 'has_hail', 'has_flood', 'has_wind', 'has_tree',\n",
    "    'has_power', 'has_damage', 'has_outage', 'has_broken', 'has_blown',\n",
    "    'tmin', 'tmax', 'tavg', 'ppt'\n",
    "]\n",
    "target_col = 'severity_class'\n",
    "\n",
    "# Prepare training features and target\n",
    "X_train = train_data[severity_features]\n",
    "y_train = train_data[target_col]\n",
    "\n",
    "# Scale training features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Prepare test features and target\n",
    "X_test = test_data[severity_features]\n",
    "y_test = test_data[target_col]\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define objective function for Optuna\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'objective': 'multiclass',\n",
    "        'num_class': len(y_train.unique()),\n",
    "        'metric': 'multi_logloss',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'min_child_weight': trial.suggest_float('min_child_weight', 1e-3, 10, log=True),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "        'random_state': 42,\n",
    "        'verbose': -1\n",
    "    }\n",
    "\n",
    "    # Train LightGBM model\n",
    "    model = lgb.LGBMClassifier(**param)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Predict and calculate accuracy\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "# Run Optuna optimization\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)  # Adjust n_trials as needed\n",
    "\n",
    "# Get best parameters\n",
    "best_params = study.best_params\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "# Train final model with best parameters\n",
    "final_params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': len(y_train.unique()),\n",
    "    'metric': 'multi_logloss',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'verbose': -1,\n",
    "    'random_state': 42,\n",
    "    **best_params\n",
    "}\n",
    "lgb_model = lgb.LGBMClassifier(**final_params)\n",
    "lgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate model on test data\n",
    "y_pred = lgb_model.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Severity Prediction Test Metrics (LightGBM):\")\n",
    "print(f\"Accuracy : {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall   : {recall:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Save the model and scaler\n",
    "# joblib.dump(lgb_model, 'severity_lgb_model.pkl')\n",
    "# joblib.dump(scaler, 'severity_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# Load training and test data\n",
    "train_data = pd.read_csv('/kaggle/input/mlpr-data-split/train.csv')\n",
    "test_data = pd.read_csv('/kaggle/input/mlpr-data-split/test.csv')\n",
    "\n",
    "# Filter for storm events\n",
    "train_data = train_data[train_data['is_storm_lagged'] == 1]\n",
    "test_data = test_data[test_data['is_storm_lagged'] == 1]\n",
    "\n",
    "# Define features and target\n",
    "severity_features = [\n",
    "    'DEATHS_INDIRECT', 'INJURIES_DIRECT', 'INJURIES_INDIRECT', 'DEATHS_DIRECT',\n",
    "    'DAMAGE_PROPERTY', 'DAMAGE_CROPS', 'customers_out', 'duration_hours',\n",
    "    'desc_word_count', 'desc_char_count',\n",
    "    'has_tornado', 'has_hail', 'has_flood', 'has_wind', 'has_tree',\n",
    "    'has_power', 'has_damage', 'has_outage', 'has_broken', 'has_blown',\n",
    "    'tmin', 'tmax', 'tavg', 'ppt'\n",
    "]\n",
    "target_col = 'severity_class'\n",
    "\n",
    "# Prepare training features and target\n",
    "X_train = train_data[severity_features]\n",
    "y_train = train_data[target_col]\n",
    "\n",
    "# Scale training features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Prepare test features and target\n",
    "X_test = test_data[severity_features]\n",
    "y_test = test_data[target_col]\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Use best parameters found via Optuna\n",
    "final_params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': len(y_train.unique()),\n",
    "    'metric': 'multi_logloss',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'verbose': -1,\n",
    "    'random_state': 42,\n",
    "    'n_estimators': 943,\n",
    "    'max_depth': 14,\n",
    "    'learning_rate': 0.299798636793099,\n",
    "    'subsample': 0.6815843772645557,\n",
    "    'colsample_bytree': 0.967548003596196,\n",
    "    'min_child_weight': 1.2892385914567714,\n",
    "    'reg_alpha': 0.009927790289736168,\n",
    "    'reg_lambda': 1.7396121269192825e-06\n",
    "}\n",
    "\n",
    "# Train final LightGBM model\n",
    "lgb_model = lgb.LGBMClassifier(**final_params)\n",
    "lgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate model on test data\n",
    "y_pred = lgb_model.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Severity Prediction Test Metrics (LightGBM):\")\n",
    "print(f\"Accuracy : {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall   : {recall:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Save the model and scaler\n",
    "# joblib.dump(lgb_model, 'severity_lgb_model.pkl')\n",
    "# joblib.dump(scaler, 'severity_scaler.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T18:20:24.374336Z",
     "iopub.status.busy": "2025-05-13T18:20:24.374013Z",
     "iopub.status.idle": "2025-05-13T19:15:40.374888Z",
     "shell.execute_reply": "2025-05-13T19:15:40.373951Z",
     "shell.execute_reply.started": "2025-05-13T18:20:24.374312Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-13 18:20:28,917] A new study created in memory with name: no-name-a4f9baf2-b36c-47a6-a3b0-04efee4e4550\n",
      "[I 2025-05-13 18:20:39,372] Trial 0 finished with value: 0.6591940976163451 and parameters: {'iterations': 441, 'depth': 5, 'learning_rate': 0.27037668043847507, 'l2_leaf_reg': 1.683330791847867e-08, 'bagging_temperature': 0.8543672325677113, 'random_strength': 2.2045047894594504e-08, 'border_count': 113}. Best is trial 0 with value: 0.6591940976163451.\n",
      "[I 2025-05-13 18:20:47,859] Trial 1 finished with value: 0.5240257283390087 and parameters: {'iterations': 471, 'depth': 3, 'learning_rate': 0.051302601906070194, 'l2_leaf_reg': 1.1283195002585259e-08, 'bagging_temperature': 0.03940533661246959, 'random_strength': 0.0008401245739724709, 'border_count': 176}. Best is trial 0 with value: 0.6591940976163451.\n",
      "[I 2025-05-13 18:20:51,250] Trial 2 finished with value: 0.511066969353008 and parameters: {'iterations': 100, 'depth': 6, 'learning_rate': 0.06203828859992205, 'l2_leaf_reg': 0.09835505320615186, 'bagging_temperature': 0.3793966454102048, 'random_strength': 4.368512973591437, 'border_count': 188}. Best is trial 0 with value: 0.6591940976163451.\n",
      "[I 2025-05-13 18:22:08,180] Trial 3 finished with value: 0.6373439273552781 and parameters: {'iterations': 563, 'depth': 10, 'learning_rate': 0.016253831846954947, 'l2_leaf_reg': 7.9638972840735e-07, 'bagging_temperature': 0.4905176147383641, 'random_strength': 1.5336617787696195e-08, 'border_count': 169}. Best is trial 0 with value: 0.6591940976163451.\n",
      "[I 2025-05-13 18:22:19,137] Trial 4 finished with value: 0.566307226636398 and parameters: {'iterations': 396, 'depth': 6, 'learning_rate': 0.0360473442146074, 'l2_leaf_reg': 1.059224835128595e-06, 'bagging_temperature': 0.6657167645106561, 'random_strength': 6.707164592843461e-07, 'border_count': 232}. Best is trial 0 with value: 0.6591940976163451.\n",
      "[I 2025-05-13 18:22:32,390] Trial 5 finished with value: 0.6166288308740068 and parameters: {'iterations': 401, 'depth': 7, 'learning_rate': 0.05435645828363996, 'l2_leaf_reg': 5.627234065374278e-08, 'bagging_temperature': 0.30535581916805166, 'random_strength': 0.08493322801055894, 'border_count': 103}. Best is trial 0 with value: 0.6591940976163451.\n",
      "[I 2025-05-13 18:23:08,347] Trial 6 finished with value: 0.7432841468028755 and parameters: {'iterations': 270, 'depth': 10, 'learning_rate': 0.12034484950684855, 'l2_leaf_reg': 0.3861895125857288, 'bagging_temperature': 0.14718805063822982, 'random_strength': 1.8107406988392715e-06, 'border_count': 155}. Best is trial 6 with value: 0.7432841468028755.\n",
      "[I 2025-05-13 18:24:16,932] Trial 7 finished with value: 0.7000567536889898 and parameters: {'iterations': 993, 'depth': 8, 'learning_rate': 0.035960970308180025, 'l2_leaf_reg': 0.029027682035164714, 'bagging_temperature': 0.625826200477212, 'random_strength': 0.0002750673355622112, 'border_count': 137}. Best is trial 6 with value: 0.7432841468028755.\n",
      "[I 2025-05-13 18:24:55,119] Trial 8 finished with value: 0.5751040484298146 and parameters: {'iterations': 512, 'depth': 8, 'learning_rate': 0.014761229180556138, 'l2_leaf_reg': 0.01582256891002646, 'bagging_temperature': 0.7277739184615835, 'random_strength': 0.07602577312747133, 'border_count': 238}. Best is trial 6 with value: 0.7432841468028755.\n",
      "[I 2025-05-13 18:25:23,086] Trial 9 finished with value: 0.6359250851305335 and parameters: {'iterations': 871, 'depth': 7, 'learning_rate': 0.0319928725766981, 'l2_leaf_reg': 6.928796124623582e-08, 'bagging_temperature': 0.7207965076710023, 'random_strength': 0.00857589900842889, 'border_count': 64}. Best is trial 6 with value: 0.7432841468028755.\n",
      "[I 2025-05-13 18:25:35,987] Trial 10 finished with value: 0.6868142262580401 and parameters: {'iterations': 115, 'depth': 10, 'learning_rate': 0.15720881004815485, 'l2_leaf_reg': 0.0002729965233385201, 'bagging_temperature': 0.06244726087238221, 'random_strength': 1.0909707761562247e-05, 'border_count': 34}. Best is trial 6 with value: 0.7432841468028755.\n",
      "[I 2025-05-13 18:27:01,315] Trial 11 finished with value: 0.7832009080590239 and parameters: {'iterations': 934, 'depth': 9, 'learning_rate': 0.13969090857526645, 'l2_leaf_reg': 5.532434085953024, 'bagging_temperature': 0.9896113906022693, 'random_strength': 4.9143368988628355e-06, 'border_count': 130}. Best is trial 11 with value: 0.7832009080590239.\n",
      "[I 2025-05-13 18:28:08,484] Trial 12 finished with value: 0.7544457056375331 and parameters: {'iterations': 737, 'depth': 9, 'learning_rate': 0.12486134451207642, 'l2_leaf_reg': 6.041811324179185, 'bagging_temperature': 0.9701158049016692, 'random_strength': 2.734796753028381e-06, 'border_count': 138}. Best is trial 11 with value: 0.7832009080590239.\n",
      "[I 2025-05-13 18:29:14,721] Trial 13 finished with value: 0.7643776012107454 and parameters: {'iterations': 762, 'depth': 9, 'learning_rate': 0.12117693792245438, 'l2_leaf_reg': 4.825769542423691, 'bagging_temperature': 0.9619606709635874, 'random_strength': 4.125170277203796e-05, 'border_count': 88}. Best is trial 11 with value: 0.7832009080590239.\n",
      "[I 2025-05-13 18:30:18,114] Trial 14 finished with value: 0.7929436246689369 and parameters: {'iterations': 726, 'depth': 9, 'learning_rate': 0.27262298806577717, 'l2_leaf_reg': 9.059897125295297, 'bagging_temperature': 0.9539906854628655, 'random_strength': 9.283555999822207e-05, 'border_count': 77}. Best is trial 14 with value: 0.7929436246689369.\n",
      "[I 2025-05-13 18:31:03,141] Trial 15 finished with value: 0.8157396897465002 and parameters: {'iterations': 676, 'depth': 8, 'learning_rate': 0.25262162467043164, 'l2_leaf_reg': 0.001032413929480421, 'bagging_temperature': 0.8534430326863767, 'random_strength': 1.7427715783147171e-07, 'border_count': 64}. Best is trial 15 with value: 0.8157396897465002.\n",
      "[I 2025-05-13 18:31:48,727] Trial 16 finished with value: 0.8221717744986757 and parameters: {'iterations': 688, 'depth': 8, 'learning_rate': 0.2952077253981401, 'l2_leaf_reg': 0.0003791424298073734, 'bagging_temperature': 0.8203352091367397, 'random_strength': 1.7208933910731797e-07, 'border_count': 35}. Best is trial 16 with value: 0.8221717744986757.\n",
      "[I 2025-05-13 18:32:01,825] Trial 17 finished with value: 0.6153045781309119 and parameters: {'iterations': 636, 'depth': 4, 'learning_rate': 0.20559413808427243, 'l2_leaf_reg': 0.0006282572071808134, 'bagging_temperature': 0.835063884215015, 'random_strength': 1.2476853943834828e-07, 'border_count': 39}. Best is trial 16 with value: 0.8221717744986757.\n",
      "[I 2025-05-13 18:32:43,340] Trial 18 finished with value: 0.7329738933030647 and parameters: {'iterations': 625, 'depth': 8, 'learning_rate': 0.08167301240208458, 'l2_leaf_reg': 0.00016714733723446695, 'bagging_temperature': 0.8288574448428577, 'random_strength': 1.8085434978773432e-07, 'border_count': 56}. Best is trial 16 with value: 0.8221717744986757.\n",
      "[I 2025-05-13 18:33:09,420] Trial 19 finished with value: 0.781309118426031 and parameters: {'iterations': 798, 'depth': 7, 'learning_rate': 0.1977206970900449, 'l2_leaf_reg': 4.34931075775226e-05, 'bagging_temperature': 0.5518287921463656, 'random_strength': 1.6691991868628818e-07, 'border_count': 55}. Best is trial 16 with value: 0.8221717744986757.\n",
      "[I 2025-05-13 18:33:25,411] Trial 20 finished with value: 0.6963677639046538 and parameters: {'iterations': 656, 'depth': 5, 'learning_rate': 0.2988018582396238, 'l2_leaf_reg': 0.005624359643981461, 'bagging_temperature': 0.7835508028136343, 'random_strength': 0.002134975283453376, 'border_count': 90}. Best is trial 16 with value: 0.8221717744986757.\n",
      "[I 2025-05-13 18:34:11,367] Trial 21 finished with value: 0.8111048051456679 and parameters: {'iterations': 692, 'depth': 8, 'learning_rate': 0.21917395941834417, 'l2_leaf_reg': 1.6123584703742456e-05, 'bagging_temperature': 0.8978311864061486, 'random_strength': 7.173754062694517e-05, 'border_count': 74}. Best is trial 16 with value: 0.8221717744986757.\n",
      "[I 2025-05-13 18:35:07,026] Trial 22 finished with value: 0.8144154370034052 and parameters: {'iterations': 834, 'depth': 8, 'learning_rate': 0.19383223281115994, 'l2_leaf_reg': 1.9468928912397e-05, 'bagging_temperature': 0.8942843313260804, 'random_strength': 2.0976123686408277e-05, 'border_count': 68}. Best is trial 16 with value: 0.8221717744986757.\n",
      "[I 2025-05-13 18:36:01,701] Trial 23 finished with value: 0.7577563374952705 and parameters: {'iterations': 832, 'depth': 8, 'learning_rate': 0.08570551642989942, 'l2_leaf_reg': 0.001850290931628122, 'bagging_temperature': 0.7568351868072373, 'random_strength': 6.349434128499859e-08, 'border_count': 38}. Best is trial 16 with value: 0.8221717744986757.\n",
      "[I 2025-05-13 18:36:30,446] Trial 24 finished with value: 0.7816874763526296 and parameters: {'iterations': 892, 'depth': 7, 'learning_rate': 0.17646608423549018, 'l2_leaf_reg': 6.162206966337906e-06, 'bagging_temperature': 0.5817806359510425, 'random_strength': 4.269294895492103e-07, 'border_count': 52}. Best is trial 16 with value: 0.8221717744986757.\n",
      "[I 2025-05-13 18:36:52,764] Trial 25 finished with value: 0.745270525917518 and parameters: {'iterations': 800, 'depth': 6, 'learning_rate': 0.2299178539890297, 'l2_leaf_reg': 6.855568593643707e-05, 'bagging_temperature': 0.8849211408122217, 'random_strength': 1.9827085445551078e-05, 'border_count': 90}. Best is trial 16 with value: 0.8221717744986757.\n",
      "[I 2025-05-13 18:37:44,077] Trial 26 finished with value: 0.7780930760499433 and parameters: {'iterations': 572, 'depth': 9, 'learning_rate': 0.09715330539212401, 'l2_leaf_reg': 0.001094131038500039, 'bagging_temperature': 0.4528182164146467, 'random_strength': 1.0145897853234343e-06, 'border_count': 117}. Best is trial 16 with value: 0.8221717744986757.\n",
      "[I 2025-05-13 18:38:56,013] Trial 27 finished with value: 0.8218880060537268 and parameters: {'iterations': 993, 'depth': 8, 'learning_rate': 0.1652960585772778, 'l2_leaf_reg': 3.449466466651407e-06, 'bagging_temperature': 0.6726608265874403, 'random_strength': 4.6055386921032394e-08, 'border_count': 205}. Best is trial 16 with value: 0.8221717744986757.\n",
      "[I 2025-05-13 18:39:08,770] Trial 28 finished with value: 0.7362845251608021 and parameters: {'iterations': 345, 'depth': 7, 'learning_rate': 0.29262637943891706, 'l2_leaf_reg': 1.56356471560938e-06, 'bagging_temperature': 0.6903729613275605, 'random_strength': 1.3393759156894857e-08, 'border_count': 206}. Best is trial 16 with value: 0.8221717744986757.\n",
      "[I 2025-05-13 18:39:31,665] Trial 29 finished with value: 0.5367007188800605 and parameters: {'iterations': 950, 'depth': 5, 'learning_rate': 0.011348188809065993, 'l2_leaf_reg': 4.892369900023781e-06, 'bagging_temperature': 0.8087256554990434, 'random_strength': 3.9351396645233297e-08, 'border_count': 212}. Best is trial 16 with value: 0.8221717744986757.\n",
      "[I 2025-05-13 18:39:49,805] Trial 30 finished with value: 0.7319334090049187 and parameters: {'iterations': 613, 'depth': 6, 'learning_rate': 0.24297248741143676, 'l2_leaf_reg': 0.004176197105786834, 'bagging_temperature': 0.6158081859958011, 'random_strength': 5.0569222701943296e-08, 'border_count': 206}. Best is trial 16 with value: 0.8221717744986757.\n",
      "[I 2025-05-13 18:40:49,837] Trial 31 finished with value: 0.8171585319712448 and parameters: {'iterations': 890, 'depth': 8, 'learning_rate': 0.16759711738757987, 'l2_leaf_reg': 2.6280903832648497e-05, 'bagging_temperature': 0.8841502065190473, 'random_strength': 4.390171099717249e-07, 'border_count': 106}. Best is trial 16 with value: 0.8221717744986757.\n",
      "[I 2025-05-13 18:42:05,457] Trial 32 finished with value: 0.8206583427922814 and parameters: {'iterations': 1000, 'depth': 8, 'learning_rate': 0.15701455725178876, 'l2_leaf_reg': 9.095325589737353e-05, 'bagging_temperature': 0.7775435416410238, 'random_strength': 3.773707612262622e-07, 'border_count': 253}. Best is trial 16 with value: 0.8221717744986757.\n",
      "[I 2025-05-13 18:43:46,707] Trial 33 finished with value: 0.8390087022323117 and parameters: {'iterations': 985, 'depth': 9, 'learning_rate': 0.14677926004960715, 'l2_leaf_reg': 2.709924526894527e-07, 'bagging_temperature': 0.7746484131580325, 'random_strength': 5.107973549565013e-07, 'border_count': 246}. Best is trial 33 with value: 0.8390087022323117.\n",
      "[I 2025-05-13 18:45:24,518] Trial 34 finished with value: 0.827090427544457 and parameters: {'iterations': 964, 'depth': 9, 'learning_rate': 0.10450380644044086, 'l2_leaf_reg': 2.2790021798944856e-07, 'bagging_temperature': 0.6607003080474892, 'random_strength': 1.101119411032926e-08, 'border_count': 223}. Best is trial 33 with value: 0.8390087022323117.\n",
      "[I 2025-05-13 18:47:37,358] Trial 35 finished with value: 0.8436435868331441 and parameters: {'iterations': 940, 'depth': 10, 'learning_rate': 0.10217686707563778, 'l2_leaf_reg': 1.5141159933277866e-07, 'bagging_temperature': 0.5261315822604151, 'random_strength': 1.0101027595267944e-08, 'border_count': 190}. Best is trial 35 with value: 0.8436435868331441.\n",
      "[I 2025-05-13 18:49:48,112] Trial 36 finished with value: 0.8232122587968218 and parameters: {'iterations': 932, 'depth': 10, 'learning_rate': 0.07043354223744634, 'l2_leaf_reg': 2.026645295373786e-07, 'bagging_temperature': 0.3738792020186099, 'random_strength': 1.0482910906650823e-08, 'border_count': 186}. Best is trial 35 with value: 0.8436435868331441.\n",
      "[I 2025-05-13 18:51:59,511] Trial 37 finished with value: 0.8204691638289822 and parameters: {'iterations': 937, 'depth': 10, 'learning_rate': 0.06733726257840474, 'l2_leaf_reg': 2.0777674955513183e-07, 'bagging_temperature': 0.30749736302213493, 'random_strength': 1.325089738721062e-08, 'border_count': 185}. Best is trial 35 with value: 0.8436435868331441.\n",
      "[I 2025-05-13 18:54:16,474] Trial 38 finished with value: 0.7963488460083239 and parameters: {'iterations': 929, 'depth': 10, 'learning_rate': 0.04804132983229983, 'l2_leaf_reg': 1.1975610567644368e-08, 'bagging_temperature': 0.42503365374628277, 'random_strength': 1.0408107387516328e-08, 'border_count': 221}. Best is trial 35 with value: 0.8436435868331441.\n",
      "[I 2025-05-13 18:56:12,650] Trial 39 finished with value: 0.8303064699205448 and parameters: {'iterations': 861, 'depth': 10, 'learning_rate': 0.09923160161530899, 'l2_leaf_reg': 3.0582901142786026e-07, 'bagging_temperature': 0.3254691433181446, 'random_strength': 4.886161925408762, 'border_count': 161}. Best is trial 35 with value: 0.8436435868331441.\n",
      "[I 2025-05-13 18:58:09,900] Trial 40 finished with value: 0.8362656072644722 and parameters: {'iterations': 861, 'depth': 10, 'learning_rate': 0.10326213748086083, 'l2_leaf_reg': 3.732137285490418e-07, 'bagging_temperature': 0.24561467163664785, 'random_strength': 2.9959149099284095, 'border_count': 167}. Best is trial 35 with value: 0.8436435868331441.\n",
      "[I 2025-05-13 19:00:06,113] Trial 41 finished with value: 0.8347521755580779 and parameters: {'iterations': 853, 'depth': 10, 'learning_rate': 0.10276630930357486, 'l2_leaf_reg': 3.7674942860281336e-07, 'bagging_temperature': 0.22254978044898396, 'random_strength': 2.8425043796399048, 'border_count': 160}. Best is trial 35 with value: 0.8436435868331441.\n",
      "[I 2025-05-13 19:02:04,184] Trial 42 finished with value: 0.8333333333333334 and parameters: {'iterations': 860, 'depth': 10, 'learning_rate': 0.09623457225374313, 'l2_leaf_reg': 4.987318898905796e-08, 'bagging_temperature': 0.2058901581903867, 'random_strength': 2.244560745521745, 'border_count': 161}. Best is trial 35 with value: 0.8436435868331441.\n",
      "[I 2025-05-13 19:03:53,686] Trial 43 finished with value: 0.8148883844116535 and parameters: {'iterations': 802, 'depth': 10, 'learning_rate': 0.0775807817633378, 'l2_leaf_reg': 6.3177571641607e-08, 'bagging_temperature': 0.18832521398680196, 'random_strength': 1.013377321050729, 'border_count': 171}. Best is trial 35 with value: 0.8436435868331441.\n",
      "[I 2025-05-13 19:05:53,535] Trial 44 finished with value: 0.8061861520998865 and parameters: {'iterations': 896, 'depth': 10, 'learning_rate': 0.058750360766199085, 'l2_leaf_reg': 3.172643083879044e-08, 'bagging_temperature': 0.17788749783613678, 'random_strength': 0.9710531930066193, 'border_count': 150}. Best is trial 35 with value: 0.8436435868331441.\n",
      "[I 2025-05-13 19:07:12,745] Trial 45 finished with value: 0.7458380628074158 and parameters: {'iterations': 848, 'depth': 9, 'learning_rate': 0.04838507148359118, 'l2_leaf_reg': 6.666395546394085e-07, 'bagging_temperature': 0.24603209846371887, 'random_strength': 1.3178541848653231, 'border_count': 162}. Best is trial 35 with value: 0.8436435868331441.\n",
      "[I 2025-05-13 19:08:59,779] Trial 46 finished with value: 0.8459137343927355 and parameters: {'iterations': 771, 'depth': 10, 'learning_rate': 0.1358607927072531, 'l2_leaf_reg': 3.698596513420882e-08, 'bagging_temperature': 0.08933994426599372, 'random_strength': 0.10544889935311012, 'border_count': 178}. Best is trial 46 with value: 0.8459137343927355.\n",
      "[I 2025-05-13 19:10:12,738] Trial 47 finished with value: 0.8193340900491866 and parameters: {'iterations': 757, 'depth': 9, 'learning_rate': 0.1310136088499942, 'l2_leaf_reg': 1.77589248656413e-08, 'bagging_temperature': 0.09102013775097773, 'random_strength': 0.11839907431257937, 'border_count': 192}. Best is trial 46 with value: 0.8459137343927355.\n",
      "[I 2025-05-13 19:12:18,686] Trial 48 finished with value: 0.8426976920166478 and parameters: {'iterations': 912, 'depth': 10, 'learning_rate': 0.11639534442065344, 'l2_leaf_reg': 5.480092588911713e-07, 'bagging_temperature': 0.00975168109588731, 'random_strength': 0.3367054688759714, 'border_count': 176}. Best is trial 46 with value: 0.8459137343927355.\n",
      "[I 2025-05-13 19:13:52,861] Trial 49 finished with value: 0.8394816496405599 and parameters: {'iterations': 968, 'depth': 9, 'learning_rate': 0.14032598648362193, 'l2_leaf_reg': 9.584663985494528e-07, 'bagging_temperature': 0.0013412310621142495, 'random_strength': 0.22073805472239735, 'border_count': 196}. Best is trial 46 with value: 0.8459137343927355.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'iterations': 771, 'depth': 10, 'learning_rate': 0.1358607927072531, 'l2_leaf_reg': 3.698596513420882e-08, 'bagging_temperature': 0.08933994426599372, 'random_strength': 0.10544889935311012, 'border_count': 178}\n",
      "Severity Prediction Test Metrics (CatBoost):\n",
      "Accuracy : 0.8459\n",
      "Precision: 0.8459\n",
      "Recall   : 0.8459\n",
      "F1 Score : 0.8458\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2866  175  165   29]\n",
      " [ 200 2416  363   52]\n",
      " [ 148  312 2638   54]\n",
      " [  25   45   61 1023]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.89      3235\n",
      "           1       0.82      0.80      0.81      3031\n",
      "           2       0.82      0.84      0.83      3152\n",
      "          10       0.88      0.89      0.88      1154\n",
      "\n",
      "    accuracy                           0.85     10572\n",
      "   macro avg       0.85      0.85      0.85     10572\n",
      "weighted avg       0.85      0.85      0.85     10572\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from catboost import CatBoostClassifier\n",
    "import optuna\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# Load training and test data\n",
    "train_data = pd.read_csv('/kaggle/input/mlpr-data-split/train.csv')\n",
    "test_data = pd.read_csv('/kaggle/input/mlpr-data-split/test.csv')\n",
    "\n",
    "# Filter for storm events\n",
    "train_data = train_data[train_data['is_storm_lagged'] == 1]\n",
    "test_data = test_data[test_data['is_storm_lagged'] == 1]\n",
    "\n",
    "# Define features and target\n",
    "severity_features = [\n",
    "    'DEATHS_INDIRECT', 'INJURIES_DIRECT', 'INJURIES_INDIRECT', 'DEATHS_DIRECT',\n",
    "    'DAMAGE_PROPERTY', 'DAMAGE_CROPS', 'customers_out', 'duration_hours',\n",
    "    'desc_word_count', 'desc_char_count',\n",
    "    'has_tornado', 'has_hail', 'has_flood', 'has_wind', 'has_tree',\n",
    "    'has_power', 'has_damage', 'has_outage', 'has_broken', 'has_blown',\n",
    "    'tmin', 'tmax', 'tavg', 'ppt'\n",
    "]\n",
    "target_col = 'severity_class'\n",
    "\n",
    "# Prepare training features and target\n",
    "X_train = train_data[severity_features]\n",
    "y_train = train_data[target_col]\n",
    "\n",
    "# Scale training features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Prepare test features and target\n",
    "X_test = test_data[severity_features]\n",
    "y_test = test_data[target_col]\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define objective function for Optuna\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'iterations': trial.suggest_int('iterations', 100, 1000),\n",
    "        'depth': trial.suggest_int('depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-8, 10.0, log=True),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n",
    "        'random_strength': trial.suggest_float('random_strength', 1e-8, 10.0, log=True),\n",
    "        'border_count': trial.suggest_int('border_count', 32, 255),\n",
    "        'loss_function': 'MultiClass',\n",
    "        'random_seed': 42,\n",
    "        'verbose': 0\n",
    "    }\n",
    "\n",
    "    # Train CatBoost model\n",
    "    model = CatBoostClassifier(**param)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Predict and calculate accuracy\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "# Run Optuna optimization\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)  # Adjust n_trials as needed\n",
    "\n",
    "# Get best parameters\n",
    "best_params = study.best_params\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "# Train final model with best parameters\n",
    "final_params = {\n",
    "    'loss_function': 'MultiClass',\n",
    "    'random_seed': 42,\n",
    "    'verbose': 0,\n",
    "    **best_params\n",
    "}\n",
    "cat_model = CatBoostClassifier(**final_params)\n",
    "cat_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate model on test data\n",
    "y_pred = cat_model.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Severity Prediction Test Metrics (CatBoost):\")\n",
    "print(f\"Accuracy : {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall   : {recall:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Save the model and scaler\n",
    "# joblib.dump(cat_model, 'severity_cat_model.pkl')\n",
    "# joblib.dump(scaler, 'severity_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T20:47:34.249760Z",
     "iopub.status.busy": "2025-05-13T20:47:34.249412Z",
     "iopub.status.idle": "2025-05-13T20:49:12.548801Z",
     "shell.execute_reply": "2025-05-13T20:49:12.547779Z",
     "shell.execute_reply.started": "2025-05-13T20:47:34.249736Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Severity Prediction Test Metrics (CatBoost):\n",
      "Accuracy : 0.9996\n",
      "Precision: 0.9996\n",
      "Recall   : 0.9996\n",
      "F1 Score : 0.9996\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3233    2    0    0]\n",
      " [   2 3029    0    0]\n",
      " [   0    0 3152    0]\n",
      " [   0    0    0 1154]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3235\n",
      "           1       1.00      1.00      1.00      3031\n",
      "           2       1.00      1.00      1.00      3152\n",
      "          10       1.00      1.00      1.00      1154\n",
      "\n",
      "    accuracy                           1.00     10572\n",
      "   macro avg       1.00      1.00      1.00     10572\n",
      "weighted avg       1.00      1.00      1.00     10572\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# Load training and test data\n",
    "train_data = pd.read_csv('/kaggle/input/mlpr-data-split/train.csv')\n",
    "test_data = pd.read_csv('/kaggle/input/mlpr-data-split/test.csv')\n",
    "\n",
    "# Filter for storm events\n",
    "train_data = train_data[train_data['is_storm_lagged'] == 1]\n",
    "test_data = test_data[test_data['is_storm_lagged'] == 1]\n",
    "\n",
    "# Define features and target\n",
    "severity_features = [\n",
    "    'DEATHS_INDIRECT', 'INJURIES_DIRECT', 'INJURIES_INDIRECT', 'DEATHS_DIRECT',\n",
    "    'DAMAGE_PROPERTY', 'DAMAGE_CROPS', 'duration_hours',\n",
    "    'desc_word_count', 'has_tornado', 'has_hail', 'has_flood', 'has_wind',\n",
    "    'has_tree', 'has_broken', 'has_blown', 'tmin', 'tmax', 'tavg', 'ppt',\n",
    "    'MAGNITUDE_IMPUTED', 'CZ_FIPS'\n",
    "]\n",
    "target_col = 'severity_class'\n",
    "\n",
    "# Prepare training features and target\n",
    "X_train = train_data[severity_features]\n",
    "y_train = train_data[target_col]\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Prepare test features and target\n",
    "X_test = test_data[severity_features]\n",
    "y_test = test_data[target_col]\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Best parameters from Optuna\n",
    "best_params = {\n",
    "    'iterations': 771,\n",
    "    'depth': 10,\n",
    "    'learning_rate': 0.1358607927072531,\n",
    "    'l2_leaf_reg': 3.698596513420882e-08,\n",
    "    'bagging_temperature': 0.08933994426599372,\n",
    "    'random_strength': 0.10544889935311012,\n",
    "    'border_count': 178,\n",
    "    'loss_function': 'MultiClass',\n",
    "    'random_seed': 42,\n",
    "    'verbose': 0\n",
    "}\n",
    "cat_model = CatBoostClassifier(**best_params)\n",
    "cat_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = cat_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Severity Prediction Test Metrics (CatBoost):\")\n",
    "print(f\"Accuracy : {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall   : {recall:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Save model and scaler (uncomment if needed)\n",
    "# joblib.dump(cat_model, 'severity_cat_model.pkl')\n",
    "# joblib.dump(scaler, 'severity_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7304854,
     "sourceId": 11641464,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
