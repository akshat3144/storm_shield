{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11641464,"sourceType":"datasetVersion","datasetId":7304854}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport joblib\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n\n# Load training and test data\ntrain_data = pd.read_csv('/kaggle/input/mlpr-data-split/train.csv')\ntest_data = pd.read_csv('/kaggle/input/mlpr-data-split/test.csv')\n\n# Filter for storm events\ntrain_data = train_data[train_data['is_storm_lagged'] == 1]\ntest_data = test_data[test_data['is_storm_lagged'] == 1]\n\n# Define features and target\nseverity_features = [\n    'DEATHS_INDIRECT', 'INJURIES_DIRECT', 'INJURIES_INDIRECT', 'DEATHS_DIRECT',\n    'DAMAGE_PROPERTY', 'DAMAGE_CROPS', 'customers_out', 'duration_hours',\n    'desc_word_count', 'desc_char_count',\n    'has_tornado', 'has_hail', 'has_flood', 'has_wind', 'has_tree',\n    'has_power', 'has_damage', 'has_outage', 'has_broken', 'has_blown',\n    'tmin', 'tmax', 'tavg', 'ppt'\n]\ntarget_col = 'severity_class'\n\n# Prepare training features and target\nX_train = train_data[severity_features]\ny_train = train_data[target_col]\n\n# Scale training features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\n\n# Initialize and train model\nrf_model = RandomForestClassifier(\n    n_estimators=201,\n    max_depth=38,\n    min_samples_split=5,\n    min_samples_leaf=2,\n    random_state=42\n)\nrf_model.fit(X_train_scaled, y_train)\n\n# Prepare test features and target\nX_test = test_data[severity_features]\ny_test = test_data[target_col]\nX_test_scaled = scaler.transform(X_test)\n\n# Evaluate model on test data\ny_pred = rf_model.predict(X_test_scaled)\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\nrecall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\nf1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\nconf_matrix = confusion_matrix(y_test, y_pred)\n\nprint(\"Severity Prediction Test Metrics:\")\nprint(f\"Accuracy : {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall   : {recall:.4f}\")\nprint(f\"F1 Score : {f1:.4f}\")\nprint(\"\\nConfusion Matrix:\")\nprint(conf_matrix)\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred, zero_division=0))\n\n# Save the model and scaler\njoblib.dump(rf_model, 'severity_rf_model.pkl')\njoblib.dump(scaler, 'severity_scaler.pkl')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T21:08:18.687132Z","iopub.execute_input":"2025-05-01T21:08:18.687754Z","iopub.status.idle":"2025-05-01T21:09:01.457668Z","shell.execute_reply.started":"2025-05-01T21:08:18.687721Z","shell.execute_reply":"2025-05-01T21:09:01.456882Z"}},"outputs":[{"name":"stdout","text":"Severity Prediction Test Metrics:\nAccuracy : 0.8441\nPrecision: 0.8441\nRecall   : 0.8441\nF1 Score : 0.8438\n\nConfusion Matrix:\n[[2868  149  177   41]\n [ 211 2390  369   61]\n [ 157  288 2645   62]\n [  29   46   58 1021]]\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.88      0.89      0.88      3235\n           1       0.83      0.79      0.81      3031\n           2       0.81      0.84      0.83      3152\n          10       0.86      0.88      0.87      1154\n\n    accuracy                           0.84     10572\n   macro avg       0.85      0.85      0.85     10572\nweighted avg       0.84      0.84      0.84     10572\n\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"['severity_scaler.pkl']"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}